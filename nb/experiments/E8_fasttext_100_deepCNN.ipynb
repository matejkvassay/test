{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import normalize as scikit_normalize\n",
    "from evaluation import plot_history\n",
    "from evaluation import rmse_report\n",
    "from sampling import UnderSampler3D\n",
    "from fasttext_embedding import FastTextEmbeddingBag\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_CHECKPOINT=True\n",
    "MODEL_SAVE_DIR='/home/kvassay/data/z/models/E8/keras_cnn.h5'\n",
    "MODEL_CHECKPOINT_PATH='/home/kvassay/data/z/models/E8/checkpoint/cp-{epoch:04d}.ckpt'\n",
    "\n",
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1_{}.pickle'\n",
    "TYPE='tok'\n",
    "TB_LOG_DIR='/home/kvassay/data/z/log/E8/scalars/'\n",
    "VEC_DIM=100\n",
    "FASTTEXT='/home/kvassay/data/z/models/fasttext/cbow_{}_e{}_w{}.bin'.format(VEC_DIM,50,5)\n",
    "SEQ_PADDING=50\n",
    "CHECKPOINT_DIR='/tmp/z/checkpoint_dim{}_pad{}/'.format(VEC_DIM,SEQ_PADDING)\n",
    "ALLOWED_SPECIAL=tuple(['?','!',':(', ':)', ':D',':-)',':-D',':\\'(',':/',':-/','<3',':-P',':P'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.59 s, sys: 1.17 s, total: 5.76 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(DATASET.format(TYPE),'rb') as f:\n",
    "    train,dev,_=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    fasttext=FastTextEmbeddingBag(FASTTEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text + extract features\n",
    "- filter out EN stop-words (and, or, ...)\n",
    "- filter out non-allowed special tokens (we want to keep smileys and !,?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_special= re.compile(\"|\".join(re.escape(s) for s in ALLOWED_SPECIAL))\n",
    "\n",
    "def word_filter(word):\n",
    "    if word in STOP_WORDS:\n",
    "        return False\n",
    "    if not word.isalpha():\n",
    "        if not rx_special.findall(word):\n",
    "            return False\n",
    "    else:\n",
    "        if len(word)<3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return [x.lower() for x in text if word_filter(x.lower())]\n",
    "\n",
    "def preprocess_texts(dataset,text_keys=['summary','text']):\n",
    "    for sample in tqdm(dataset):\n",
    "        for key in text_keys:\n",
    "            sample[key]=preprocess_text(sample[key])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 11.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    train=preprocess_texts(train)\n",
    "    dev=preprocess_texts(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "- transform texts to averages of their fastText vectors\n",
    "- concatenate summary & text average vectors into single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_vecs(vecs_mtx,length):\n",
    "    return pad_sequences(vecs_mtx,\n",
    "                         maxlen=length,\n",
    "                         dtype='float32',\n",
    "                        padding='post',\n",
    "                        truncating='post')\n",
    "\n",
    "def extract_features(dataset, fasttext):\n",
    "    default_vec=np.zeros(VEC_DIM,dtype=np.float32)\n",
    "    vecs_all=[]\n",
    "    for sample in tqdm(dataset):\n",
    "        all_words=sample['summary']+sample['text']\n",
    "        if all_words:\n",
    "            vecs=fasttext.forward([x for x in all_words])\n",
    "        else:\n",
    "            vecs=np.array([default_vec])\n",
    "        vecs=scikit_normalize(vecs)\n",
    "        vecs=vecs.reshape(1,vecs.shape[0],vecs.shape[1])         \n",
    "        vecs = pad_vecs(vecs, SEQ_PADDING)\n",
    "        vecs_all.append(vecs)\n",
    "    vecs_all=np.array(vecs_all)\n",
    "    vecs_all=vecs_all.reshape(vecs_all.shape[0],vecs_all.shape[2],vecs_all.shape[3])\n",
    "    return vecs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    with open(CHECKPOINT_DIR+'X_train.npy','rb') as f:\n",
    "        X_train=np.load(f)\n",
    "    with open(CHECKPOINT_DIR+'X_dev.npy','rb') as f:\n",
    "        X_dev=np.load(f)\n",
    "    with open(CHECKPOINT_DIR+'y_train.npy','rb') as f:\n",
    "        y_train=np.load(f)\n",
    "    with open(CHECKPOINT_DIR+'y_dev.npy','rb') as f:\n",
    "        y_dev=np.load(f)\n",
    "    return X_train,X_dev,y_train,y_dev\n",
    "        \n",
    "def checkpoint(X_train,X_dev,y_train,y_dev):\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        os.makedirs(CHECKPOINT_DIR)\n",
    "    with open(CHECKPOINT_DIR+'X_train.npy','wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    with open(CHECKPOINT_DIR+'X_dev.npy','wb') as f:\n",
    "        np.save(f,X_dev)\n",
    "    with open(CHECKPOINT_DIR+'y_train.npy','wb') as f:\n",
    "        np.save(f,y_train)\n",
    "    with open(CHECKPOINT_DIR+'y_dev.npy','wb') as f:\n",
    "        np.save(f,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.3 ms, sys: 5.98 s, total: 6.07 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    X_train=extract_features(train,fasttext)\n",
    "    X_dev=extract_features(dev,fasttext)\n",
    "    y_train=np.array([x['score'] for x in train])\n",
    "    y_dev=np.array([x['score'] for x in dev])\n",
    "    print('Train samples shape: {}, Dev samples shape: {}'.format(X_train.shape,X_dev.shape))\n",
    "else:\n",
    "    X_train,X_dev,y_train,y_dev=load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3 µs, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    checkpoint(X_train,X_dev,y_train,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(learning_rate,epochs,batch_size,name,steps):\n",
    "    model=train_model(epochs=epochs,batch_size=batch_size,learning_rate=learning_rate,steps=steps)\n",
    "    y_pred_dev=model.predict(X_dev)\n",
    "    rmse_report(y_dev,y_pred_dev,title='{} - RMSE report'.format(name))\n",
    "    plot_history(model,title='{} - Train/Dev MSE'.format(name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tb_callback():\n",
    "    suffix=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir= os.path.join(TB_LOG_DIR,suffix)\n",
    "    return K.callbacks.TensorBoard(log_dir=os.path.join(log_dir))\n",
    "\n",
    "def penalized_loss(y_true, y_pred):\n",
    "    return K.backend.mean(K.backend.square(K.backend.abs(y_true - y_pred))/y_true)\n",
    "\n",
    "def train_model(batch_size,learning_rate, epochs,steps):\n",
    "    DROPRATE=0.05\n",
    "    \n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(MODEL_CHECKPOINT_PATH,\n",
    "                                                     verbose=1,\n",
    "                                                     save_weights_only=False,\n",
    "                                                     period=50)\n",
    "    \n",
    "    tensorboard_callback = get_tb_callback()\n",
    "    model = K.models.Sequential([\n",
    "        K.layers.Conv1D(256, 3, activation='relu',strides=2,padding='same',\n",
    "                        input_shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        K.layers.MaxPooling1D(3),\n",
    "        K.layers.Dropout(DROPRATE),\n",
    "        K.layers.BatchNormalization(),\n",
    "        K.layers.Conv1D(256, 3, activation='relu',strides=2,padding='same',\n",
    "                        input_shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        K.layers.MaxPooling1D(3),\n",
    "        K.layers.Dropout(DROPRATE),\n",
    "        K.layers.BatchNormalization(),\n",
    "        K.layers.Conv1D(256, 3, activation='relu',strides=2,padding='same',\n",
    "                        input_shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        K.layers.GlobalMaxPooling1D(),\n",
    "        K.layers.Dropout(DROPRATE),\n",
    "        K.layers.BatchNormalization(),\n",
    "        K.layers.Dense(256,activation='relu'),\n",
    "        K.layers.Dense(1,activation='linear')])\n",
    "    opt=K.optimizers.Adam(lr=learning_rate, decay=learning_rate/epochs)\n",
    "    model.compile(optimizer=opt, loss=penalized_loss,metrics=[penalized_loss])\n",
    "    sampler=UnderSampler3D(X_train,y_train,batch_size=batch_size)\n",
    "    model.fit_generator(sampler,\n",
    "                        shuffle=False,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps,\n",
    "                        validation_data=(X_dev,y_dev),\n",
    "                        callbacks=[tensorboard_callback,cp_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 10:22:33.615246 140247743416128 callbacks.py:862] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 1.7685 - penalized_loss: 1.7685 - val_loss: 0.8540 - val_penalized_loss: 0.8540\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4561 - penalized_loss: 0.4561 - val_loss: 0.5886 - val_penalized_loss: 0.5886\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.4131 - penalized_loss: 0.4131 - val_loss: 0.4247 - val_penalized_loss: 0.4247\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4095 - penalized_loss: 0.4095 - val_loss: 0.7406 - val_penalized_loss: 0.7406\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3849 - penalized_loss: 0.3849 - val_loss: 0.3670 - val_penalized_loss: 0.3670\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.3733 - penalized_loss: 0.3733 - val_loss: 0.3831 - val_penalized_loss: 0.3831\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3572 - penalized_loss: 0.3572 - val_loss: 0.4048 - val_penalized_loss: 0.4048\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3561 - penalized_loss: 0.3561 - val_loss: 0.4768 - val_penalized_loss: 0.4768\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3572 - penalized_loss: 0.3572 - val_loss: 0.3350 - val_penalized_loss: 0.3350\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3543 - penalized_loss: 0.3543 - val_loss: 0.3937 - val_penalized_loss: 0.3937\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3453 - penalized_loss: 0.3453 - val_loss: 0.5578 - val_penalized_loss: 0.5578\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3333 - penalized_loss: 0.3333 - val_loss: 0.3071 - val_penalized_loss: 0.3071\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.3343 - penalized_loss: 0.3343 - val_loss: 0.3297 - val_penalized_loss: 0.3297\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3431 - penalized_loss: 0.3431 - val_loss: 0.3543 - val_penalized_loss: 0.3543\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.3319 - penalized_loss: 0.3319 - val_loss: 0.3639 - val_penalized_loss: 0.3639\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.3235 - penalized_loss: 0.3235 - val_loss: 0.3274 - val_penalized_loss: 0.3274\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.3256 - penalized_loss: 0.3256 - val_loss: 0.3959 - val_penalized_loss: 0.3959\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3134 - penalized_loss: 0.3134 - val_loss: 0.4042 - val_penalized_loss: 0.4042\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.3202 - penalized_loss: 0.3202 - val_loss: 0.3492 - val_penalized_loss: 0.3492\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3150 - penalized_loss: 0.3150 - val_loss: 0.3562 - val_penalized_loss: 0.3562\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.3188 - penalized_loss: 0.3188 - val_loss: 0.3178 - val_penalized_loss: 0.3178\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.3169 - penalized_loss: 0.3169 - val_loss: 0.2977 - val_penalized_loss: 0.2977\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.3138 - penalized_loss: 0.3138 - val_loss: 0.3448 - val_penalized_loss: 0.3448\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.3056 - penalized_loss: 0.3056 - val_loss: 0.2585 - val_penalized_loss: 0.2585\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3008 - penalized_loss: 0.3008 - val_loss: 0.2796 - val_penalized_loss: 0.2796\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.3085 - penalized_loss: 0.3085 - val_loss: 0.3014 - val_penalized_loss: 0.3014\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3004 - penalized_loss: 0.3004 - val_loss: 0.3633 - val_penalized_loss: 0.3633\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.3012 - penalized_loss: 0.3012 - val_loss: 0.4574 - val_penalized_loss: 0.4574\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2897 - penalized_loss: 0.2897 - val_loss: 0.2814 - val_penalized_loss: 0.2814\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.2835 - penalized_loss: 0.2835 - val_loss: 0.3735 - val_penalized_loss: 0.3735\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.2906 - penalized_loss: 0.2906 - val_loss: 0.2826 - val_penalized_loss: 0.2826\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2880 - penalized_loss: 0.2880 - val_loss: 0.3332 - val_penalized_loss: 0.3332\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.2945 - penalized_loss: 0.2945 - val_loss: 0.3498 - val_penalized_loss: 0.3498\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.2902 - penalized_loss: 0.2902 - val_loss: 0.3068 - val_penalized_loss: 0.3068\n",
      "Epoch 35/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.2674 - penalized_loss: 0.2674 - val_loss: 0.3031 - val_penalized_loss: 0.3031\n",
      "Epoch 36/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.2776 - penalized_loss: 0.2776 - val_loss: 0.2765 - val_penalized_loss: 0.2765\n",
      "Epoch 37/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.2771 - penalized_loss: 0.2771 - val_loss: 0.3021 - val_penalized_loss: 0.3021\n",
      "Epoch 38/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.2732 - penalized_loss: 0.2732 - val_loss: 0.4560 - val_penalized_loss: 0.4560\n",
      "Epoch 39/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.2890 - penalized_loss: 0.2890 - val_loss: 0.3204 - val_penalized_loss: 0.3204\n",
      "Epoch 40/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.2681 - penalized_loss: 0.2681 - val_loss: 0.2559 - val_penalized_loss: 0.2559\n",
      "Epoch 41/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2707 - penalized_loss: 0.2707 - val_loss: 0.2810 - val_penalized_loss: 0.2810\n",
      "Epoch 42/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2643 - penalized_loss: 0.2643 - val_loss: 0.2941 - val_penalized_loss: 0.2941\n",
      "Epoch 43/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.2758 - penalized_loss: 0.2758 - val_loss: 0.3176 - val_penalized_loss: 0.3176\n",
      "Epoch 44/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.2713 - penalized_loss: 0.2713 - val_loss: 0.3322 - val_penalized_loss: 0.3322\n",
      "Epoch 45/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.2617 - penalized_loss: 0.2617 - val_loss: 0.3122 - val_penalized_loss: 0.3122\n",
      "Epoch 46/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2538 - penalized_loss: 0.2538 - val_loss: 0.2891 - val_penalized_loss: 0.2891\n",
      "Epoch 47/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.2555 - penalized_loss: 0.2555 - val_loss: 0.3282 - val_penalized_loss: 0.3282\n",
      "Epoch 48/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.2586 - penalized_loss: 0.2586 - val_loss: 0.2355 - val_penalized_loss: 0.2355\n",
      "Epoch 49/1000\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.2538 - penalized_loss: 0.2538 - val_loss: 0.2639 - val_penalized_loss: 0.2639\n",
      "Epoch 50/1000\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.2568 - penalized_loss: 0.2568\n",
      "Epoch 00050: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0050.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 10:30:54.747246 140247743416128 deprecation.py:506] From /home/kvassay/.virtualenvs/main/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 12s 61ms/step - loss: 0.2568 - penalized_loss: 0.2568 - val_loss: 0.3561 - val_penalized_loss: 0.3561\n",
      "Epoch 51/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.2530 - penalized_loss: 0.2530 - val_loss: 0.2514 - val_penalized_loss: 0.2514\n",
      "Epoch 52/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.2414 - penalized_loss: 0.2414 - val_loss: 0.2860 - val_penalized_loss: 0.2860\n",
      "Epoch 53/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2469 - penalized_loss: 0.2469 - val_loss: 0.2661 - val_penalized_loss: 0.2661\n",
      "Epoch 54/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.2428 - penalized_loss: 0.2428 - val_loss: 0.2962 - val_penalized_loss: 0.2962\n",
      "Epoch 55/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2421 - penalized_loss: 0.2421 - val_loss: 0.3050 - val_penalized_loss: 0.3050\n",
      "Epoch 56/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.2487 - penalized_loss: 0.2487 - val_loss: 0.2423 - val_penalized_loss: 0.2423\n",
      "Epoch 57/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.2377 - penalized_loss: 0.2377 - val_loss: 0.2402 - val_penalized_loss: 0.2402\n",
      "Epoch 58/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.2279 - penalized_loss: 0.2279 - val_loss: 0.2519 - val_penalized_loss: 0.2519\n",
      "Epoch 59/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.2296 - penalized_loss: 0.2296 - val_loss: 0.2701 - val_penalized_loss: 0.2701\n",
      "Epoch 60/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.2288 - penalized_loss: 0.2288 - val_loss: 0.2874 - val_penalized_loss: 0.2874\n",
      "Epoch 61/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.2411 - penalized_loss: 0.2411 - val_loss: 0.3028 - val_penalized_loss: 0.3028\n",
      "Epoch 62/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2309 - penalized_loss: 0.2309 - val_loss: 0.3134 - val_penalized_loss: 0.3134\n",
      "Epoch 63/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.2160 - penalized_loss: 0.2160 - val_loss: 0.3043 - val_penalized_loss: 0.3043\n",
      "Epoch 64/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2181 - penalized_loss: 0.2181 - val_loss: 0.2678 - val_penalized_loss: 0.2678\n",
      "Epoch 65/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2253 - penalized_loss: 0.2253 - val_loss: 0.2391 - val_penalized_loss: 0.2391\n",
      "Epoch 66/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.2247 - penalized_loss: 0.2247 - val_loss: 0.2523 - val_penalized_loss: 0.2523\n",
      "Epoch 67/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2270 - penalized_loss: 0.2270 - val_loss: 0.2282 - val_penalized_loss: 0.2282\n",
      "Epoch 68/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.2284 - penalized_loss: 0.2284 - val_loss: 0.2275 - val_penalized_loss: 0.2275\n",
      "Epoch 69/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2113 - penalized_loss: 0.2113 - val_loss: 0.2718 - val_penalized_loss: 0.2718\n",
      "Epoch 70/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.2115 - penalized_loss: 0.2115 - val_loss: 0.2971 - val_penalized_loss: 0.2971\n",
      "Epoch 71/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2169 - penalized_loss: 0.2169 - val_loss: 0.2478 - val_penalized_loss: 0.2478\n",
      "Epoch 72/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.2100 - penalized_loss: 0.2100 - val_loss: 0.2305 - val_penalized_loss: 0.2305\n",
      "Epoch 73/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.2187 - penalized_loss: 0.2187 - val_loss: 0.2652 - val_penalized_loss: 0.2652\n",
      "Epoch 74/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2093 - penalized_loss: 0.2093 - val_loss: 0.2096 - val_penalized_loss: 0.2096\n",
      "Epoch 75/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.2030 - penalized_loss: 0.2030 - val_loss: 0.2350 - val_penalized_loss: 0.2350\n",
      "Epoch 76/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2009 - penalized_loss: 0.2009 - val_loss: 0.2397 - val_penalized_loss: 0.2397\n",
      "Epoch 77/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.2088 - penalized_loss: 0.2088 - val_loss: 0.2577 - val_penalized_loss: 0.2577\n",
      "Epoch 78/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2081 - penalized_loss: 0.2081 - val_loss: 0.2604 - val_penalized_loss: 0.2604\n",
      "Epoch 79/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2153 - penalized_loss: 0.2153 - val_loss: 0.2554 - val_penalized_loss: 0.2554\n",
      "Epoch 80/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1925 - penalized_loss: 0.1925 - val_loss: 0.2526 - val_penalized_loss: 0.2526\n",
      "Epoch 81/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1936 - penalized_loss: 0.1936 - val_loss: 0.2324 - val_penalized_loss: 0.2324\n",
      "Epoch 82/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1965 - penalized_loss: 0.1965 - val_loss: 0.2218 - val_penalized_loss: 0.2218\n",
      "Epoch 83/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1959 - penalized_loss: 0.1959 - val_loss: 0.2604 - val_penalized_loss: 0.2604\n",
      "Epoch 84/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.2025 - penalized_loss: 0.2025 - val_loss: 0.2169 - val_penalized_loss: 0.2169\n",
      "Epoch 85/1000\n",
      "200/200 [==============================] - 13s 67ms/step - loss: 0.1956 - penalized_loss: 0.1956 - val_loss: 0.2455 - val_penalized_loss: 0.2455\n",
      "Epoch 86/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1856 - penalized_loss: 0.1856 - val_loss: 0.2297 - val_penalized_loss: 0.2297\n",
      "Epoch 87/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1944 - penalized_loss: 0.1944 - val_loss: 0.2758 - val_penalized_loss: 0.2758\n",
      "Epoch 88/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1936 - penalized_loss: 0.1936 - val_loss: 0.2758 - val_penalized_loss: 0.2758\n",
      "Epoch 89/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.2023 - penalized_loss: 0.2023 - val_loss: 0.2860 - val_penalized_loss: 0.2860\n",
      "Epoch 90/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2031 - penalized_loss: 0.2031 - val_loss: 0.2769 - val_penalized_loss: 0.2769\n",
      "Epoch 91/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1880 - penalized_loss: 0.1880 - val_loss: 0.2218 - val_penalized_loss: 0.2218\n",
      "Epoch 92/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1807 - penalized_loss: 0.1807 - val_loss: 0.2642 - val_penalized_loss: 0.2642\n",
      "Epoch 93/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1828 - penalized_loss: 0.1828 - val_loss: 0.6867 - val_penalized_loss: 0.6867\n",
      "Epoch 94/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1850 - penalized_loss: 0.1850 - val_loss: 0.3111 - val_penalized_loss: 0.3111\n",
      "Epoch 95/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1896 - penalized_loss: 0.1896 - val_loss: 0.3196 - val_penalized_loss: 0.3196\n",
      "Epoch 96/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1848 - penalized_loss: 0.1848 - val_loss: 1.3132 - val_penalized_loss: 1.3132\n",
      "Epoch 97/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1738 - penalized_loss: 0.1738 - val_loss: 1.3768 - val_penalized_loss: 1.3768\n",
      "Epoch 98/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1768 - penalized_loss: 0.1768 - val_loss: 0.2219 - val_penalized_loss: 0.2219\n",
      "Epoch 99/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1782 - penalized_loss: 0.1782 - val_loss: 0.8128 - val_penalized_loss: 0.8128\n",
      "Epoch 100/1000\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.1798 - penalized_loss: 0.1798\n",
      "Epoch 00100: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0100.ckpt\n",
      "200/200 [==============================] - 12s 61ms/step - loss: 0.1794 - penalized_loss: 0.1794 - val_loss: 0.4883 - val_penalized_loss: 0.4883\n",
      "Epoch 101/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1808 - penalized_loss: 0.1808 - val_loss: 0.2576 - val_penalized_loss: 0.2576\n",
      "Epoch 102/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.1744 - penalized_loss: 0.1744 - val_loss: 0.2776 - val_penalized_loss: 0.2776\n",
      "Epoch 103/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1690 - penalized_loss: 0.1690 - val_loss: 0.2711 - val_penalized_loss: 0.2711\n",
      "Epoch 104/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1693 - penalized_loss: 0.1693 - val_loss: 0.2737 - val_penalized_loss: 0.2737\n",
      "Epoch 105/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1743 - penalized_loss: 0.1743 - val_loss: 0.2252 - val_penalized_loss: 0.2252\n",
      "Epoch 106/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1774 - penalized_loss: 0.1774 - val_loss: 1.2189 - val_penalized_loss: 1.2189\n",
      "Epoch 107/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1767 - penalized_loss: 0.1767 - val_loss: 0.3148 - val_penalized_loss: 0.3148\n",
      "Epoch 108/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.1649 - penalized_loss: 0.1649 - val_loss: 0.5919 - val_penalized_loss: 0.5919\n",
      "Epoch 109/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1641 - penalized_loss: 0.1641 - val_loss: 2.9740 - val_penalized_loss: 2.9740\n",
      "Epoch 110/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1660 - penalized_loss: 0.1660 - val_loss: 0.2569 - val_penalized_loss: 0.2569\n",
      "Epoch 111/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1726 - penalized_loss: 0.1726 - val_loss: 0.2604 - val_penalized_loss: 0.2604\n",
      "Epoch 112/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1662 - penalized_loss: 0.1662 - val_loss: 0.2440 - val_penalized_loss: 0.2440\n",
      "Epoch 113/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.1665 - penalized_loss: 0.1665 - val_loss: 0.2185 - val_penalized_loss: 0.2185\n",
      "Epoch 114/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.1590 - penalized_loss: 0.1590 - val_loss: 0.3700 - val_penalized_loss: 0.3700\n",
      "Epoch 115/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1599 - penalized_loss: 0.1599 - val_loss: 0.2625 - val_penalized_loss: 0.2625\n",
      "Epoch 116/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1633 - penalized_loss: 0.1633 - val_loss: 0.2327 - val_penalized_loss: 0.2327\n",
      "Epoch 117/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1652 - penalized_loss: 0.1652 - val_loss: 0.3997 - val_penalized_loss: 0.3997\n",
      "Epoch 118/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1605 - penalized_loss: 0.1605 - val_loss: 0.2396 - val_penalized_loss: 0.2396\n",
      "Epoch 119/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.1622 - penalized_loss: 0.1622 - val_loss: 0.2209 - val_penalized_loss: 0.2209\n",
      "Epoch 120/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1529 - penalized_loss: 0.1529 - val_loss: 0.3024 - val_penalized_loss: 0.3024\n",
      "Epoch 121/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1574 - penalized_loss: 0.1574 - val_loss: 0.2026 - val_penalized_loss: 0.2026\n",
      "Epoch 122/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1615 - penalized_loss: 0.1615 - val_loss: 0.2051 - val_penalized_loss: 0.2051\n",
      "Epoch 123/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1623 - penalized_loss: 0.1623 - val_loss: 0.2207 - val_penalized_loss: 0.2207\n",
      "Epoch 124/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1649 - penalized_loss: 0.1649 - val_loss: 0.2163 - val_penalized_loss: 0.2163\n",
      "Epoch 125/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.1511 - penalized_loss: 0.1511 - val_loss: 45.0098 - val_penalized_loss: 45.0098\n",
      "Epoch 126/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1483 - penalized_loss: 0.1483 - val_loss: 0.2100 - val_penalized_loss: 0.2100\n",
      "Epoch 127/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1573 - penalized_loss: 0.1573 - val_loss: 0.2314 - val_penalized_loss: 0.2314\n",
      "Epoch 128/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1597 - penalized_loss: 0.1597 - val_loss: 0.2279 - val_penalized_loss: 0.2279\n",
      "Epoch 129/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1597 - penalized_loss: 0.1597 - val_loss: 0.2345 - val_penalized_loss: 0.2345\n",
      "Epoch 130/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.1585 - penalized_loss: 0.1585 - val_loss: 0.2038 - val_penalized_loss: 0.2038\n",
      "Epoch 131/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1481 - penalized_loss: 0.1481 - val_loss: 0.2662 - val_penalized_loss: 0.2662\n",
      "Epoch 132/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1495 - penalized_loss: 0.1495 - val_loss: 0.2254 - val_penalized_loss: 0.2254\n",
      "Epoch 133/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1489 - penalized_loss: 0.1489 - val_loss: 0.2068 - val_penalized_loss: 0.2068\n",
      "Epoch 134/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1556 - penalized_loss: 0.1556 - val_loss: 0.1997 - val_penalized_loss: 0.1997\n",
      "Epoch 135/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1603 - penalized_loss: 0.1603 - val_loss: 0.2014 - val_penalized_loss: 0.2014\n",
      "Epoch 136/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1478 - penalized_loss: 0.1478 - val_loss: 0.2041 - val_penalized_loss: 0.2041\n",
      "Epoch 137/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1423 - penalized_loss: 0.1423 - val_loss: 0.2082 - val_penalized_loss: 0.2082\n",
      "Epoch 138/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1493 - penalized_loss: 0.1493 - val_loss: 0.2761 - val_penalized_loss: 0.2761\n",
      "Epoch 139/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1473 - penalized_loss: 0.1473 - val_loss: 1.4996 - val_penalized_loss: 1.4996\n",
      "Epoch 140/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1485 - penalized_loss: 0.1485 - val_loss: 0.2179 - val_penalized_loss: 0.2179\n",
      "Epoch 141/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1504 - penalized_loss: 0.1504 - val_loss: 0.2122 - val_penalized_loss: 0.2122\n",
      "Epoch 142/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1533 - penalized_loss: 0.1533 - val_loss: 9.8797 - val_penalized_loss: 9.8797\n",
      "Epoch 143/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1663 - penalized_loss: 0.1663 - val_loss: 0.2241 - val_penalized_loss: 0.2241\n",
      "Epoch 144/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1596 - penalized_loss: 0.1596 - val_loss: 0.2231 - val_penalized_loss: 0.2231\n",
      "Epoch 145/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1525 - penalized_loss: 0.1525 - val_loss: 0.2065 - val_penalized_loss: 0.2065\n",
      "Epoch 146/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1531 - penalized_loss: 0.1531 - val_loss: 0.2049 - val_penalized_loss: 0.2049\n",
      "Epoch 147/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.1472 - penalized_loss: 0.1472 - val_loss: 0.2100 - val_penalized_loss: 0.2100\n",
      "Epoch 148/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1429 - penalized_loss: 0.1429 - val_loss: 0.2431 - val_penalized_loss: 0.2431\n",
      "Epoch 149/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1340 - penalized_loss: 0.1340 - val_loss: 0.7537 - val_penalized_loss: 0.7537\n",
      "Epoch 150/1000\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.1413 - penalized_loss: 0.1413\n",
      "Epoch 00150: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0150.ckpt\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.1415 - penalized_loss: 0.1415 - val_loss: 11.5643 - val_penalized_loss: 11.5643\n",
      "Epoch 151/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1497 - penalized_loss: 0.1497 - val_loss: 3.2576 - val_penalized_loss: 3.2576\n",
      "Epoch 152/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1485 - penalized_loss: 0.1485 - val_loss: 0.2975 - val_penalized_loss: 0.2975\n",
      "Epoch 153/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.1359 - penalized_loss: 0.1359 - val_loss: 0.3756 - val_penalized_loss: 0.3756\n",
      "Epoch 154/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.1327 - penalized_loss: 0.1327 - val_loss: 0.2040 - val_penalized_loss: 0.2040\n",
      "Epoch 155/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1388 - penalized_loss: 0.1388 - val_loss: 0.2049 - val_penalized_loss: 0.2049\n",
      "Epoch 156/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1413 - penalized_loss: 0.1413 - val_loss: 0.2289 - val_penalized_loss: 0.2289\n",
      "Epoch 157/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1408 - penalized_loss: 0.1408 - val_loss: 0.2072 - val_penalized_loss: 0.2072\n",
      "Epoch 158/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.1401 - penalized_loss: 0.1401 - val_loss: 5.1580 - val_penalized_loss: 5.1580\n",
      "Epoch 159/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1286 - penalized_loss: 0.1286 - val_loss: 0.2019 - val_penalized_loss: 0.2019\n",
      "Epoch 160/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1345 - penalized_loss: 0.1345 - val_loss: 0.2278 - val_penalized_loss: 0.2278\n",
      "Epoch 161/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.1365 - penalized_loss: 0.1365 - val_loss: 0.2025 - val_penalized_loss: 0.2025\n",
      "Epoch 162/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1377 - penalized_loss: 0.1377 - val_loss: 0.2517 - val_penalized_loss: 0.2517\n",
      "Epoch 163/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1404 - penalized_loss: 0.1404 - val_loss: 89.7539 - val_penalized_loss: 89.7540\n",
      "Epoch 164/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.1317 - penalized_loss: 0.1317 - val_loss: 188.1127 - val_penalized_loss: 188.1127\n",
      "Epoch 165/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1274 - penalized_loss: 0.1274 - val_loss: 43.4618 - val_penalized_loss: 43.4618\n",
      "Epoch 166/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1274 - penalized_loss: 0.1274 - val_loss: 210.9689 - val_penalized_loss: 210.9689\n",
      "Epoch 167/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1344 - penalized_loss: 0.1344 - val_loss: 2.6229 - val_penalized_loss: 2.6229\n",
      "Epoch 168/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1343 - penalized_loss: 0.1343 - val_loss: 20.8544 - val_penalized_loss: 20.8544\n",
      "Epoch 169/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1350 - penalized_loss: 0.1350 - val_loss: 14.5891 - val_penalized_loss: 14.5891\n",
      "Epoch 170/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1261 - penalized_loss: 0.1261 - val_loss: 18.6900 - val_penalized_loss: 18.6900\n",
      "Epoch 171/1000\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.1254 - penalized_loss: 0.1254 - val_loss: 0.4023 - val_penalized_loss: 0.4023\n",
      "Epoch 172/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1294 - penalized_loss: 0.1294 - val_loss: 0.3387 - val_penalized_loss: 0.3387\n",
      "Epoch 173/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1369 - penalized_loss: 0.1369 - val_loss: 0.2127 - val_penalized_loss: 0.2127\n",
      "Epoch 174/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1338 - penalized_loss: 0.1338 - val_loss: 74.5296 - val_penalized_loss: 74.5296\n",
      "Epoch 175/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.1319 - penalized_loss: 0.1319 - val_loss: 77.0096 - val_penalized_loss: 77.0096\n",
      "Epoch 176/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1244 - penalized_loss: 0.1244 - val_loss: 346.5997 - val_penalized_loss: 346.5996\n",
      "Epoch 177/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1249 - penalized_loss: 0.1249 - val_loss: 39.7345 - val_penalized_loss: 39.7345\n",
      "Epoch 178/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1245 - penalized_loss: 0.1245 - val_loss: 418.0212 - val_penalized_loss: 418.0212\n",
      "Epoch 179/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.1304 - penalized_loss: 0.1304 - val_loss: 17.0039 - val_penalized_loss: 17.0039\n",
      "Epoch 180/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1317 - penalized_loss: 0.1317 - val_loss: 23.9704 - val_penalized_loss: 23.9704\n",
      "Epoch 181/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.1263 - penalized_loss: 0.1263 - val_loss: 20.3357 - val_penalized_loss: 20.3357\n",
      "Epoch 182/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1216 - penalized_loss: 0.1216 - val_loss: 8.1272 - val_penalized_loss: 8.1272\n",
      "Epoch 183/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1242 - penalized_loss: 0.1242 - val_loss: 0.3434 - val_penalized_loss: 0.3434\n",
      "Epoch 184/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1305 - penalized_loss: 0.1305 - val_loss: 0.1994 - val_penalized_loss: 0.1994\n",
      "Epoch 185/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1291 - penalized_loss: 0.1291 - val_loss: 0.2740 - val_penalized_loss: 0.2740\n",
      "Epoch 186/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1293 - penalized_loss: 0.1293 - val_loss: 0.2110 - val_penalized_loss: 0.2110\n",
      "Epoch 187/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.1222 - penalized_loss: 0.1222 - val_loss: 0.2330 - val_penalized_loss: 0.2330\n",
      "Epoch 188/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1203 - penalized_loss: 0.1203 - val_loss: 0.1980 - val_penalized_loss: 0.1980\n",
      "Epoch 189/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1178 - penalized_loss: 0.1178 - val_loss: 0.2431 - val_penalized_loss: 0.2431\n",
      "Epoch 190/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1229 - penalized_loss: 0.1229 - val_loss: 10.0161 - val_penalized_loss: 10.0161\n",
      "Epoch 191/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1286 - penalized_loss: 0.1286 - val_loss: 0.4235 - val_penalized_loss: 0.4235\n",
      "Epoch 192/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1244 - penalized_loss: 0.1244 - val_loss: 0.2380 - val_penalized_loss: 0.2380\n",
      "Epoch 193/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1178 - penalized_loss: 0.1178 - val_loss: 0.2521 - val_penalized_loss: 0.2521\n",
      "Epoch 194/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1208 - penalized_loss: 0.1208 - val_loss: 0.2533 - val_penalized_loss: 0.2533\n",
      "Epoch 195/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1185 - penalized_loss: 0.1185 - val_loss: 0.6133 - val_penalized_loss: 0.6133\n",
      "Epoch 196/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1237 - penalized_loss: 0.1237 - val_loss: 0.6566 - val_penalized_loss: 0.6566\n",
      "Epoch 197/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1196 - penalized_loss: 0.1196 - val_loss: 0.3443 - val_penalized_loss: 0.3443\n",
      "Epoch 198/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.1189 - penalized_loss: 0.1189 - val_loss: 11.4818 - val_penalized_loss: 11.4818\n",
      "Epoch 199/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1209 - penalized_loss: 0.1209 - val_loss: 0.2074 - val_penalized_loss: 0.2074\n",
      "Epoch 200/1000\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.1191 - penalized_loss: 0.1191\n",
      "Epoch 00200: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0200.ckpt\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.1193 - penalized_loss: 0.1193 - val_loss: 0.2512 - val_penalized_loss: 0.2512\n",
      "Epoch 201/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1257 - penalized_loss: 0.1257 - val_loss: 0.2190 - val_penalized_loss: 0.2190\n",
      "Epoch 202/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1185 - penalized_loss: 0.1185 - val_loss: 0.2120 - val_penalized_loss: 0.2120\n",
      "Epoch 203/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1274 - penalized_loss: 0.1274 - val_loss: 0.2001 - val_penalized_loss: 0.2001\n",
      "Epoch 204/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.1143 - penalized_loss: 0.1143 - val_loss: 0.1987 - val_penalized_loss: 0.1987\n",
      "Epoch 205/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1175 - penalized_loss: 0.1175 - val_loss: 0.1992 - val_penalized_loss: 0.1992\n",
      "Epoch 206/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1155 - penalized_loss: 0.1155 - val_loss: 0.2223 - val_penalized_loss: 0.2223\n",
      "Epoch 207/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1110 - penalized_loss: 0.1110 - val_loss: 0.2209 - val_penalized_loss: 0.2209\n",
      "Epoch 208/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1170 - penalized_loss: 0.1170 - val_loss: 0.2019 - val_penalized_loss: 0.2019\n",
      "Epoch 209/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.1146 - penalized_loss: 0.1146 - val_loss: 0.2461 - val_penalized_loss: 0.2461\n",
      "Epoch 210/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1134 - penalized_loss: 0.1134 - val_loss: 0.1952 - val_penalized_loss: 0.1952\n",
      "Epoch 211/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1180 - penalized_loss: 0.1180 - val_loss: 0.2063 - val_penalized_loss: 0.2063\n",
      "Epoch 212/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1167 - penalized_loss: 0.1167 - val_loss: 0.2033 - val_penalized_loss: 0.2033\n",
      "Epoch 213/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1199 - penalized_loss: 0.1199 - val_loss: 0.2119 - val_penalized_loss: 0.2119\n",
      "Epoch 214/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1183 - penalized_loss: 0.1183 - val_loss: 0.1996 - val_penalized_loss: 0.1996\n",
      "Epoch 215/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1118 - penalized_loss: 0.1118 - val_loss: 0.2240 - val_penalized_loss: 0.2240\n",
      "Epoch 216/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1179 - penalized_loss: 0.1179 - val_loss: 0.1982 - val_penalized_loss: 0.1982\n",
      "Epoch 217/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1178 - penalized_loss: 0.1178 - val_loss: 0.2512 - val_penalized_loss: 0.2512\n",
      "Epoch 218/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1133 - penalized_loss: 0.1133 - val_loss: 0.2561 - val_penalized_loss: 0.2561\n",
      "Epoch 219/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1187 - penalized_loss: 0.1187 - val_loss: 0.2140 - val_penalized_loss: 0.2140\n",
      "Epoch 220/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1163 - penalized_loss: 0.1163 - val_loss: 0.2366 - val_penalized_loss: 0.2366\n",
      "Epoch 221/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1070 - penalized_loss: 0.1070 - val_loss: 1.8783 - val_penalized_loss: 1.8783\n",
      "Epoch 222/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1097 - penalized_loss: 0.1097 - val_loss: 0.2532 - val_penalized_loss: 0.2532\n",
      "Epoch 223/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1119 - penalized_loss: 0.1119 - val_loss: 0.2499 - val_penalized_loss: 0.2499\n",
      "Epoch 224/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1138 - penalized_loss: 0.1138 - val_loss: 0.3219 - val_penalized_loss: 0.3219\n",
      "Epoch 225/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1180 - penalized_loss: 0.1180 - val_loss: 0.2094 - val_penalized_loss: 0.2094\n",
      "Epoch 226/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.1083 - penalized_loss: 0.1083 - val_loss: 0.2449 - val_penalized_loss: 0.2449\n",
      "Epoch 227/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1067 - penalized_loss: 0.1067 - val_loss: 0.2087 - val_penalized_loss: 0.2087\n",
      "Epoch 228/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1098 - penalized_loss: 0.1098 - val_loss: 0.3172 - val_penalized_loss: 0.3172\n",
      "Epoch 229/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1125 - penalized_loss: 0.1125 - val_loss: 0.2932 - val_penalized_loss: 0.2932\n",
      "Epoch 230/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1125 - penalized_loss: 0.1125 - val_loss: 0.2374 - val_penalized_loss: 0.2374\n",
      "Epoch 231/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1119 - penalized_loss: 0.1119 - val_loss: 0.3078 - val_penalized_loss: 0.3078\n",
      "Epoch 232/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.1073 - penalized_loss: 0.1073 - val_loss: 0.2696 - val_penalized_loss: 0.2696\n",
      "Epoch 233/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1066 - penalized_loss: 0.1066 - val_loss: 0.2191 - val_penalized_loss: 0.2191\n",
      "Epoch 234/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1062 - penalized_loss: 0.1062 - val_loss: 0.2050 - val_penalized_loss: 0.2050\n",
      "Epoch 235/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1113 - penalized_loss: 0.1113 - val_loss: 0.2114 - val_penalized_loss: 0.2114\n",
      "Epoch 236/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1121 - penalized_loss: 0.1121 - val_loss: 0.5227 - val_penalized_loss: 0.5227\n",
      "Epoch 237/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.1132 - penalized_loss: 0.1132 - val_loss: 0.2084 - val_penalized_loss: 0.2084\n",
      "Epoch 238/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1073 - penalized_loss: 0.1073 - val_loss: 0.6871 - val_penalized_loss: 0.6871\n",
      "Epoch 239/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1083 - penalized_loss: 0.1083 - val_loss: 0.6913 - val_penalized_loss: 0.6913\n",
      "Epoch 240/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1044 - penalized_loss: 0.1044 - val_loss: 0.9952 - val_penalized_loss: 0.9952\n",
      "Epoch 241/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1077 - penalized_loss: 0.1077 - val_loss: 0.5402 - val_penalized_loss: 0.5402\n",
      "Epoch 242/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1088 - penalized_loss: 0.1088 - val_loss: 1.6627 - val_penalized_loss: 1.6627\n",
      "Epoch 243/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.1061 - penalized_loss: 0.1061 - val_loss: 0.2049 - val_penalized_loss: 0.2049\n",
      "Epoch 244/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1036 - penalized_loss: 0.1036 - val_loss: 0.2064 - val_penalized_loss: 0.2064\n",
      "Epoch 245/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1072 - penalized_loss: 0.1072 - val_loss: 0.2002 - val_penalized_loss: 0.2002\n",
      "Epoch 246/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1057 - penalized_loss: 0.1057 - val_loss: 0.4022 - val_penalized_loss: 0.4022\n",
      "Epoch 247/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1066 - penalized_loss: 0.1066 - val_loss: 0.4158 - val_penalized_loss: 0.4158\n",
      "Epoch 248/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1109 - penalized_loss: 0.1109 - val_loss: 0.7763 - val_penalized_loss: 0.7763\n",
      "Epoch 249/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.1040 - penalized_loss: 0.1040 - val_loss: 3.4502 - val_penalized_loss: 3.4502\n",
      "Epoch 250/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.1042 - penalized_loss: 0.1042\n",
      "Epoch 00250: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0250.ckpt\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 0.1043 - penalized_loss: 0.1043 - val_loss: 0.2287 - val_penalized_loss: 0.2287\n",
      "Epoch 251/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1049 - penalized_loss: 0.1049 - val_loss: 0.2408 - val_penalized_loss: 0.2408\n",
      "Epoch 252/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1082 - penalized_loss: 0.1082 - val_loss: 0.8856 - val_penalized_loss: 0.8856\n",
      "Epoch 253/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1060 - penalized_loss: 0.1060 - val_loss: 0.3131 - val_penalized_loss: 0.3131\n",
      "Epoch 254/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.1069 - penalized_loss: 0.1069 - val_loss: 0.3004 - val_penalized_loss: 0.3004\n",
      "Epoch 255/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0973 - penalized_loss: 0.0973 - val_loss: 0.2311 - val_penalized_loss: 0.2311\n",
      "Epoch 256/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0999 - penalized_loss: 0.0999 - val_loss: 0.8893 - val_penalized_loss: 0.8893\n",
      "Epoch 257/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1044 - penalized_loss: 0.1044 - val_loss: 0.2199 - val_penalized_loss: 0.2199\n",
      "Epoch 258/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1025 - penalized_loss: 0.1025 - val_loss: 0.2719 - val_penalized_loss: 0.2719\n",
      "Epoch 259/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1040 - penalized_loss: 0.1040 - val_loss: 0.2171 - val_penalized_loss: 0.2171\n",
      "Epoch 260/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0996 - penalized_loss: 0.0996 - val_loss: 0.3787 - val_penalized_loss: 0.3787\n",
      "Epoch 261/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0998 - penalized_loss: 0.0998 - val_loss: 0.2929 - val_penalized_loss: 0.2929\n",
      "Epoch 262/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1010 - penalized_loss: 0.1010 - val_loss: 0.2392 - val_penalized_loss: 0.2392\n",
      "Epoch 263/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1050 - penalized_loss: 0.1050 - val_loss: 0.2066 - val_penalized_loss: 0.2066\n",
      "Epoch 264/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1055 - penalized_loss: 0.1055 - val_loss: 0.2157 - val_penalized_loss: 0.2157\n",
      "Epoch 265/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1107 - penalized_loss: 0.1107 - val_loss: 0.2699 - val_penalized_loss: 0.2699\n",
      "Epoch 266/1000\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.1042 - penalized_loss: 0.1042 - val_loss: 0.2616 - val_penalized_loss: 0.2616\n",
      "Epoch 267/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.1008 - penalized_loss: 0.1008 - val_loss: 0.2610 - val_penalized_loss: 0.2610\n",
      "Epoch 268/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1031 - penalized_loss: 0.1031 - val_loss: 0.2011 - val_penalized_loss: 0.2011\n",
      "Epoch 269/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1054 - penalized_loss: 0.1054 - val_loss: 0.1975 - val_penalized_loss: 0.1975\n",
      "Epoch 270/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1018 - penalized_loss: 0.1018 - val_loss: 0.2223 - val_penalized_loss: 0.2223\n",
      "Epoch 271/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.1011 - penalized_loss: 0.1011 - val_loss: 0.2814 - val_penalized_loss: 0.2814\n",
      "Epoch 272/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0964 - penalized_loss: 0.0964 - val_loss: 3.0550 - val_penalized_loss: 3.0550\n",
      "Epoch 273/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0994 - penalized_loss: 0.0994 - val_loss: 0.2060 - val_penalized_loss: 0.2060\n",
      "Epoch 274/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.1021 - penalized_loss: 0.1021 - val_loss: 0.2119 - val_penalized_loss: 0.2119\n",
      "Epoch 275/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1004 - penalized_loss: 0.1004 - val_loss: 0.2277 - val_penalized_loss: 0.2277\n",
      "Epoch 276/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1007 - penalized_loss: 0.1007 - val_loss: 1.9762 - val_penalized_loss: 1.9762\n",
      "Epoch 277/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.1014 - penalized_loss: 0.1014 - val_loss: 792.6576 - val_penalized_loss: 792.6576\n",
      "Epoch 278/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0962 - penalized_loss: 0.0962 - val_loss: 23.8786 - val_penalized_loss: 23.8786\n",
      "Epoch 279/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.1004 - penalized_loss: 0.1004 - val_loss: 99.6228 - val_penalized_loss: 99.6227\n",
      "Epoch 280/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1016 - penalized_loss: 0.1016 - val_loss: 146.1611 - val_penalized_loss: 146.1611\n",
      "Epoch 281/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1000 - penalized_loss: 0.1000 - val_loss: 5.7153 - val_penalized_loss: 5.7153\n",
      "Epoch 282/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.1055 - penalized_loss: 0.1055 - val_loss: 1.0281 - val_penalized_loss: 1.0281\n",
      "Epoch 283/1000\n",
      "200/200 [==============================] - 14s 68ms/step - loss: 0.0978 - penalized_loss: 0.0978 - val_loss: 0.2130 - val_penalized_loss: 0.2130\n",
      "Epoch 284/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0965 - penalized_loss: 0.0965 - val_loss: 0.5215 - val_penalized_loss: 0.5215\n",
      "Epoch 285/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0966 - penalized_loss: 0.0966 - val_loss: 0.3324 - val_penalized_loss: 0.3324\n",
      "Epoch 286/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0988 - penalized_loss: 0.0988 - val_loss: 0.4342 - val_penalized_loss: 0.4342\n",
      "Epoch 287/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1000 - penalized_loss: 0.1000 - val_loss: 3.5001 - val_penalized_loss: 3.5001\n",
      "Epoch 288/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0974 - penalized_loss: 0.0974 - val_loss: 19.3890 - val_penalized_loss: 19.3890\n",
      "Epoch 289/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.1007 - penalized_loss: 0.1007 - val_loss: 34.2048 - val_penalized_loss: 34.2047\n",
      "Epoch 290/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1050 - penalized_loss: 0.1050 - val_loss: 59.9180 - val_penalized_loss: 59.9180\n",
      "Epoch 291/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0978 - penalized_loss: 0.0978 - val_loss: 422.9991 - val_penalized_loss: 422.9991\n",
      "Epoch 292/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0980 - penalized_loss: 0.0980 - val_loss: 0.2056 - val_penalized_loss: 0.2056\n",
      "Epoch 293/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0987 - penalized_loss: 0.0987 - val_loss: 73.1383 - val_penalized_loss: 73.1383\n",
      "Epoch 294/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0958 - penalized_loss: 0.0958 - val_loss: 2172.7524 - val_penalized_loss: 2172.7527\n",
      "Epoch 295/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0948 - penalized_loss: 0.0948 - val_loss: 1.5723 - val_penalized_loss: 1.5723\n",
      "Epoch 296/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0966 - penalized_loss: 0.0966 - val_loss: 0.4491 - val_penalized_loss: 0.4491\n",
      "Epoch 297/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0933 - penalized_loss: 0.0933 - val_loss: 25.8210 - val_penalized_loss: 25.8210\n",
      "Epoch 298/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0962 - penalized_loss: 0.0962 - val_loss: 507.3140 - val_penalized_loss: 507.3141\n",
      "Epoch 299/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.0989 - penalized_loss: 0.0989 - val_loss: 8.3291 - val_penalized_loss: 8.3291\n",
      "Epoch 300/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0905 - penalized_loss: 0.0905\n",
      "Epoch 00300: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0300.ckpt\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.0905 - penalized_loss: 0.0905 - val_loss: 7.7189 - val_penalized_loss: 7.7189\n",
      "Epoch 301/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0932 - penalized_loss: 0.0932 - val_loss: 1191.7790 - val_penalized_loss: 1191.7786\n",
      "Epoch 302/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0962 - penalized_loss: 0.0962 - val_loss: 109.8739 - val_penalized_loss: 109.8739\n",
      "Epoch 303/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0951 - penalized_loss: 0.0951 - val_loss: 1879.3533 - val_penalized_loss: 1879.3531\n",
      "Epoch 304/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.0977 - penalized_loss: 0.0977 - val_loss: 1730.8428 - val_penalized_loss: 1730.8430\n",
      "Epoch 305/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0948 - penalized_loss: 0.0948 - val_loss: 0.4902 - val_penalized_loss: 0.4902\n",
      "Epoch 306/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0930 - penalized_loss: 0.0930 - val_loss: 4.6696 - val_penalized_loss: 4.6696\n",
      "Epoch 307/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0970 - penalized_loss: 0.0970 - val_loss: 26.7914 - val_penalized_loss: 26.7914\n",
      "Epoch 308/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0966 - penalized_loss: 0.0966 - val_loss: 394.0150 - val_penalized_loss: 394.0150\n",
      "Epoch 309/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0951 - penalized_loss: 0.0951 - val_loss: 3.1585 - val_penalized_loss: 3.1585\n",
      "Epoch 310/1000\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0996 - penalized_loss: 0.0996 - val_loss: 0.7091 - val_penalized_loss: 0.7091\n",
      "Epoch 311/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.0950 - penalized_loss: 0.0950 - val_loss: 0.2537 - val_penalized_loss: 0.2537\n",
      "Epoch 312/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0918 - penalized_loss: 0.0918 - val_loss: 3.1121 - val_penalized_loss: 3.1121\n",
      "Epoch 313/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0947 - penalized_loss: 0.0947 - val_loss: 0.5570 - val_penalized_loss: 0.5570\n",
      "Epoch 314/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0904 - penalized_loss: 0.0904 - val_loss: 1.6790 - val_penalized_loss: 1.6790\n",
      "Epoch 315/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0924 - penalized_loss: 0.0924 - val_loss: 0.6862 - val_penalized_loss: 0.6862\n",
      "Epoch 316/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.0927 - penalized_loss: 0.0927 - val_loss: 0.6453 - val_penalized_loss: 0.6453\n",
      "Epoch 317/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0942 - penalized_loss: 0.0942 - val_loss: 1.1812 - val_penalized_loss: 1.1812\n",
      "Epoch 318/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0896 - penalized_loss: 0.0896 - val_loss: 0.5680 - val_penalized_loss: 0.5680\n",
      "Epoch 319/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0921 - penalized_loss: 0.0921 - val_loss: 15.6216 - val_penalized_loss: 15.6216\n",
      "Epoch 320/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0910 - penalized_loss: 0.0910 - val_loss: 0.8309 - val_penalized_loss: 0.8309\n",
      "Epoch 321/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0916 - penalized_loss: 0.0916 - val_loss: 0.3586 - val_penalized_loss: 0.3586\n",
      "Epoch 322/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0922 - penalized_loss: 0.0922 - val_loss: 0.2400 - val_penalized_loss: 0.2400\n",
      "Epoch 323/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0923 - penalized_loss: 0.0923 - val_loss: 0.2195 - val_penalized_loss: 0.2195\n",
      "Epoch 324/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0924 - penalized_loss: 0.0924 - val_loss: 0.6420 - val_penalized_loss: 0.6420\n",
      "Epoch 325/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0918 - penalized_loss: 0.0918 - val_loss: 1.7577 - val_penalized_loss: 1.7577\n",
      "Epoch 326/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0907 - penalized_loss: 0.0907 - val_loss: 2.0009 - val_penalized_loss: 2.0009\n",
      "Epoch 327/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0949 - penalized_loss: 0.0949 - val_loss: 2.8106 - val_penalized_loss: 2.8106\n",
      "Epoch 328/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0936 - penalized_loss: 0.0936 - val_loss: 3.9656 - val_penalized_loss: 3.9656\n",
      "Epoch 329/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0948 - penalized_loss: 0.0948 - val_loss: 34.3721 - val_penalized_loss: 34.3721\n",
      "Epoch 330/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0940 - penalized_loss: 0.0940 - val_loss: 0.2704 - val_penalized_loss: 0.2704\n",
      "Epoch 331/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0898 - penalized_loss: 0.0898 - val_loss: 0.2081 - val_penalized_loss: 0.2081\n",
      "Epoch 332/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0907 - penalized_loss: 0.0907 - val_loss: 0.3547 - val_penalized_loss: 0.3547\n",
      "Epoch 333/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0893 - penalized_loss: 0.0893 - val_loss: 0.2305 - val_penalized_loss: 0.2305\n",
      "Epoch 334/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0875 - penalized_loss: 0.0875 - val_loss: 0.2146 - val_penalized_loss: 0.2146\n",
      "Epoch 335/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0917 - penalized_loss: 0.0917 - val_loss: 0.2388 - val_penalized_loss: 0.2388\n",
      "Epoch 336/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0915 - penalized_loss: 0.0915 - val_loss: 0.2746 - val_penalized_loss: 0.2746\n",
      "Epoch 337/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0903 - penalized_loss: 0.0903 - val_loss: 0.4066 - val_penalized_loss: 0.4066\n",
      "Epoch 338/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0932 - penalized_loss: 0.0932 - val_loss: 0.2880 - val_penalized_loss: 0.2880\n",
      "Epoch 339/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.0872 - penalized_loss: 0.0872 - val_loss: 0.2886 - val_penalized_loss: 0.2886\n",
      "Epoch 340/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0868 - penalized_loss: 0.0868 - val_loss: 0.2193 - val_penalized_loss: 0.2193\n",
      "Epoch 341/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0884 - penalized_loss: 0.0884 - val_loss: 9.2763 - val_penalized_loss: 9.2763\n",
      "Epoch 342/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0912 - penalized_loss: 0.0912 - val_loss: 0.2034 - val_penalized_loss: 0.2034\n",
      "Epoch 343/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0915 - penalized_loss: 0.0915 - val_loss: 0.1954 - val_penalized_loss: 0.1954\n",
      "Epoch 344/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0918 - penalized_loss: 0.0918 - val_loss: 0.2327 - val_penalized_loss: 0.2327\n",
      "Epoch 345/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0851 - penalized_loss: 0.0851 - val_loss: 0.2107 - val_penalized_loss: 0.2107\n",
      "Epoch 346/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0878 - penalized_loss: 0.0878 - val_loss: 0.1946 - val_penalized_loss: 0.1946\n",
      "Epoch 347/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0854 - penalized_loss: 0.0854 - val_loss: 0.3341 - val_penalized_loss: 0.3341\n",
      "Epoch 348/1000\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0927 - penalized_loss: 0.0927 - val_loss: 0.2008 - val_penalized_loss: 0.2008\n",
      "Epoch 349/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0896 - penalized_loss: 0.0896 - val_loss: 0.1923 - val_penalized_loss: 0.1923\n",
      "Epoch 350/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0914 - penalized_loss: 0.0914\n",
      "Epoch 00350: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0350.ckpt\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.0913 - penalized_loss: 0.0913 - val_loss: 0.1922 - val_penalized_loss: 0.1922\n",
      "Epoch 351/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0900 - penalized_loss: 0.0900 - val_loss: 0.2296 - val_penalized_loss: 0.2296\n",
      "Epoch 352/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0868 - penalized_loss: 0.0868 - val_loss: 0.2112 - val_penalized_loss: 0.2112\n",
      "Epoch 353/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0866 - penalized_loss: 0.0866 - val_loss: 0.2275 - val_penalized_loss: 0.2275\n",
      "Epoch 354/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0878 - penalized_loss: 0.0878 - val_loss: 0.2058 - val_penalized_loss: 0.2058\n",
      "Epoch 355/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0908 - penalized_loss: 0.0908 - val_loss: 0.6778 - val_penalized_loss: 0.6778\n",
      "Epoch 356/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0857 - penalized_loss: 0.0857 - val_loss: 0.3127 - val_penalized_loss: 0.3127\n",
      "Epoch 357/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0843 - penalized_loss: 0.0843 - val_loss: 0.1991 - val_penalized_loss: 0.1991\n",
      "Epoch 358/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0884 - penalized_loss: 0.0884 - val_loss: 0.2068 - val_penalized_loss: 0.2068\n",
      "Epoch 359/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0899 - penalized_loss: 0.0899 - val_loss: 0.2135 - val_penalized_loss: 0.2135\n",
      "Epoch 360/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0890 - penalized_loss: 0.0890 - val_loss: 1.4747 - val_penalized_loss: 1.4747\n",
      "Epoch 361/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0902 - penalized_loss: 0.0902 - val_loss: 90.0463 - val_penalized_loss: 90.0463\n",
      "Epoch 362/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0841 - penalized_loss: 0.0841 - val_loss: 536.8314 - val_penalized_loss: 536.8315\n",
      "Epoch 363/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0862 - penalized_loss: 0.0862 - val_loss: 0.3174 - val_penalized_loss: 0.3174\n",
      "Epoch 364/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0858 - penalized_loss: 0.0858 - val_loss: 0.4860 - val_penalized_loss: 0.4860\n",
      "Epoch 365/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0868 - penalized_loss: 0.0868 - val_loss: 0.3349 - val_penalized_loss: 0.3349\n",
      "Epoch 366/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0886 - penalized_loss: 0.0886 - val_loss: 0.5714 - val_penalized_loss: 0.5714\n",
      "Epoch 367/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0876 - penalized_loss: 0.0876 - val_loss: 0.3769 - val_penalized_loss: 0.3769\n",
      "Epoch 368/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0856 - penalized_loss: 0.0856 - val_loss: 0.2158 - val_penalized_loss: 0.2158\n",
      "Epoch 369/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0838 - penalized_loss: 0.0838 - val_loss: 0.2377 - val_penalized_loss: 0.2377\n",
      "Epoch 370/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0858 - penalized_loss: 0.0858 - val_loss: 0.4814 - val_penalized_loss: 0.4814\n",
      "Epoch 371/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0877 - penalized_loss: 0.0877 - val_loss: 3.9313 - val_penalized_loss: 3.9313\n",
      "Epoch 372/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0859 - penalized_loss: 0.0859 - val_loss: 0.7626 - val_penalized_loss: 0.7626\n",
      "Epoch 373/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.0839 - penalized_loss: 0.0839 - val_loss: 0.2380 - val_penalized_loss: 0.2380\n",
      "Epoch 374/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0863 - penalized_loss: 0.0863 - val_loss: 0.4594 - val_penalized_loss: 0.4594\n",
      "Epoch 375/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0860 - penalized_loss: 0.0860 - val_loss: 0.5930 - val_penalized_loss: 0.5930\n",
      "Epoch 376/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.0856 - penalized_loss: 0.0856 - val_loss: 0.9308 - val_penalized_loss: 0.9308\n",
      "Epoch 377/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0842 - penalized_loss: 0.0842 - val_loss: 2.3327 - val_penalized_loss: 2.3327\n",
      "Epoch 378/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.0845 - penalized_loss: 0.0845 - val_loss: 0.2029 - val_penalized_loss: 0.2029\n",
      "Epoch 379/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0806 - penalized_loss: 0.0806 - val_loss: 0.2654 - val_penalized_loss: 0.2654\n",
      "Epoch 380/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0837 - penalized_loss: 0.0837 - val_loss: 0.5401 - val_penalized_loss: 0.5401\n",
      "Epoch 381/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0847 - penalized_loss: 0.0847 - val_loss: 0.5845 - val_penalized_loss: 0.5845\n",
      "Epoch 382/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0851 - penalized_loss: 0.0851 - val_loss: 0.8481 - val_penalized_loss: 0.8481\n",
      "Epoch 383/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0849 - penalized_loss: 0.0849 - val_loss: 0.2534 - val_penalized_loss: 0.2534\n",
      "Epoch 384/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0841 - penalized_loss: 0.0841 - val_loss: 0.1942 - val_penalized_loss: 0.1942\n",
      "Epoch 385/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0871 - penalized_loss: 0.0871 - val_loss: 0.2076 - val_penalized_loss: 0.2076\n",
      "Epoch 386/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0850 - penalized_loss: 0.0850 - val_loss: 0.2461 - val_penalized_loss: 0.2461\n",
      "Epoch 387/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0843 - penalized_loss: 0.0843 - val_loss: 0.3143 - val_penalized_loss: 0.3143\n",
      "Epoch 388/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0857 - penalized_loss: 0.0857 - val_loss: 0.2771 - val_penalized_loss: 0.2771\n",
      "Epoch 389/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0872 - penalized_loss: 0.0872 - val_loss: 0.2269 - val_penalized_loss: 0.2269\n",
      "Epoch 390/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0808 - penalized_loss: 0.0808 - val_loss: 0.3985 - val_penalized_loss: 0.3985\n",
      "Epoch 391/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0826 - penalized_loss: 0.0826 - val_loss: 1.6577 - val_penalized_loss: 1.6577\n",
      "Epoch 392/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0824 - penalized_loss: 0.0824 - val_loss: 2.6020 - val_penalized_loss: 2.6020\n",
      "Epoch 393/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0839 - penalized_loss: 0.0839 - val_loss: 1.6454 - val_penalized_loss: 1.6454\n",
      "Epoch 394/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0851 - penalized_loss: 0.0851 - val_loss: 0.2171 - val_penalized_loss: 0.2171\n",
      "Epoch 395/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0857 - penalized_loss: 0.0857 - val_loss: 0.1952 - val_penalized_loss: 0.1952\n",
      "Epoch 396/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0863 - penalized_loss: 0.0863 - val_loss: 0.2753 - val_penalized_loss: 0.2753\n",
      "Epoch 397/1000\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.0866 - penalized_loss: 0.0866 - val_loss: 0.4400 - val_penalized_loss: 0.4400\n",
      "Epoch 398/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0832 - penalized_loss: 0.0832 - val_loss: 0.1967 - val_penalized_loss: 0.1967\n",
      "Epoch 399/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0845 - penalized_loss: 0.0845 - val_loss: 0.2027 - val_penalized_loss: 0.2027\n",
      "Epoch 400/1000\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.0824 - penalized_loss: 0.0824\n",
      "Epoch 00400: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0400.ckpt\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.0823 - penalized_loss: 0.0823 - val_loss: 0.2027 - val_penalized_loss: 0.2027\n",
      "Epoch 401/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0828 - penalized_loss: 0.0828 - val_loss: 0.2064 - val_penalized_loss: 0.2064\n",
      "Epoch 402/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0787 - penalized_loss: 0.0787 - val_loss: 0.1990 - val_penalized_loss: 0.1990\n",
      "Epoch 403/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0843 - penalized_loss: 0.0843 - val_loss: 0.2210 - val_penalized_loss: 0.2210\n",
      "Epoch 404/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0852 - penalized_loss: 0.0852 - val_loss: 0.2671 - val_penalized_loss: 0.2671\n",
      "Epoch 405/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0821 - penalized_loss: 0.0821 - val_loss: 0.1993 - val_penalized_loss: 0.1993\n",
      "Epoch 406/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0825 - penalized_loss: 0.0825 - val_loss: 0.1964 - val_penalized_loss: 0.1964\n",
      "Epoch 407/1000\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 0.0812 - penalized_loss: 0.0812 - val_loss: 0.1934 - val_penalized_loss: 0.1934\n",
      "Epoch 408/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0826 - penalized_loss: 0.0826 - val_loss: 0.2144 - val_penalized_loss: 0.2144\n",
      "Epoch 409/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0808 - penalized_loss: 0.0808 - val_loss: 0.2219 - val_penalized_loss: 0.2219\n",
      "Epoch 410/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0802 - penalized_loss: 0.0802 - val_loss: 0.2349 - val_penalized_loss: 0.2349\n",
      "Epoch 411/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0803 - penalized_loss: 0.0803 - val_loss: 0.1964 - val_penalized_loss: 0.1964\n",
      "Epoch 412/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.0824 - penalized_loss: 0.0824 - val_loss: 0.1969 - val_penalized_loss: 0.1969\n",
      "Epoch 413/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0775 - penalized_loss: 0.0775 - val_loss: 0.2034 - val_penalized_loss: 0.2034\n",
      "Epoch 414/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0791 - penalized_loss: 0.0791 - val_loss: 0.2033 - val_penalized_loss: 0.2033\n",
      "Epoch 415/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0800 - penalized_loss: 0.0800 - val_loss: 0.2051 - val_penalized_loss: 0.2051\n",
      "Epoch 416/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0816 - penalized_loss: 0.0816 - val_loss: 0.2106 - val_penalized_loss: 0.2106\n",
      "Epoch 417/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0800 - penalized_loss: 0.0800 - val_loss: 0.2387 - val_penalized_loss: 0.2387\n",
      "Epoch 418/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.0815 - penalized_loss: 0.0815 - val_loss: 0.1985 - val_penalized_loss: 0.1985\n",
      "Epoch 419/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0786 - penalized_loss: 0.0786 - val_loss: 0.2219 - val_penalized_loss: 0.2219\n",
      "Epoch 420/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0817 - penalized_loss: 0.0817 - val_loss: 0.2012 - val_penalized_loss: 0.2012\n",
      "Epoch 421/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0792 - penalized_loss: 0.0792 - val_loss: 0.1962 - val_penalized_loss: 0.1962\n",
      "Epoch 422/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0824 - penalized_loss: 0.0824 - val_loss: 0.2019 - val_penalized_loss: 0.2019\n",
      "Epoch 423/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0821 - penalized_loss: 0.0821 - val_loss: 0.1917 - val_penalized_loss: 0.1917\n",
      "Epoch 424/1000\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 0.0798 - penalized_loss: 0.0798 - val_loss: 0.6131 - val_penalized_loss: 0.6131\n",
      "Epoch 425/1000\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.0784 - penalized_loss: 0.0784 - val_loss: 0.3088 - val_penalized_loss: 0.3088\n",
      "Epoch 426/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0792 - penalized_loss: 0.0792 - val_loss: 0.1909 - val_penalized_loss: 0.1909\n",
      "Epoch 427/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0822 - penalized_loss: 0.0822 - val_loss: 0.2092 - val_penalized_loss: 0.2092\n",
      "Epoch 428/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0815 - penalized_loss: 0.0815 - val_loss: 0.1933 - val_penalized_loss: 0.1933\n",
      "Epoch 429/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0778 - penalized_loss: 0.0778 - val_loss: 0.1956 - val_penalized_loss: 0.1956\n",
      "Epoch 430/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0783 - penalized_loss: 0.0783 - val_loss: 0.1935 - val_penalized_loss: 0.1935\n",
      "Epoch 431/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0779 - penalized_loss: 0.0779 - val_loss: 0.2099 - val_penalized_loss: 0.2099\n",
      "Epoch 432/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0809 - penalized_loss: 0.0809 - val_loss: 0.1920 - val_penalized_loss: 0.1920\n",
      "Epoch 433/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0794 - penalized_loss: 0.0794 - val_loss: 0.2079 - val_penalized_loss: 0.2079\n",
      "Epoch 434/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0810 - penalized_loss: 0.0810 - val_loss: 2.8840 - val_penalized_loss: 2.8840\n",
      "Epoch 435/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0792 - penalized_loss: 0.0792 - val_loss: 0.1992 - val_penalized_loss: 0.1992\n",
      "Epoch 436/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0749 - penalized_loss: 0.0749 - val_loss: 0.1965 - val_penalized_loss: 0.1965\n",
      "Epoch 437/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0771 - penalized_loss: 0.0771 - val_loss: 0.2026 - val_penalized_loss: 0.2026\n",
      "Epoch 438/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0764 - penalized_loss: 0.0764 - val_loss: 0.2455 - val_penalized_loss: 0.2455\n",
      "Epoch 439/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0774 - penalized_loss: 0.0774 - val_loss: 0.2660 - val_penalized_loss: 0.2660\n",
      "Epoch 440/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0794 - penalized_loss: 0.0794 - val_loss: 0.7537 - val_penalized_loss: 0.7537\n",
      "Epoch 441/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0771 - penalized_loss: 0.0771 - val_loss: 0.4808 - val_penalized_loss: 0.4808\n",
      "Epoch 442/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0770 - penalized_loss: 0.0770 - val_loss: 0.5996 - val_penalized_loss: 0.5996\n",
      "Epoch 443/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0787 - penalized_loss: 0.0787 - val_loss: 0.3500 - val_penalized_loss: 0.3500\n",
      "Epoch 444/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0806 - penalized_loss: 0.0806 - val_loss: 0.3244 - val_penalized_loss: 0.3244\n",
      "Epoch 445/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0784 - penalized_loss: 0.0784 - val_loss: 0.1948 - val_penalized_loss: 0.1948\n",
      "Epoch 446/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0814 - penalized_loss: 0.0814 - val_loss: 0.2730 - val_penalized_loss: 0.2730\n",
      "Epoch 447/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0836 - penalized_loss: 0.0836 - val_loss: 0.2092 - val_penalized_loss: 0.2092\n",
      "Epoch 448/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0800 - penalized_loss: 0.0800 - val_loss: 0.3242 - val_penalized_loss: 0.3242\n",
      "Epoch 449/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0784 - penalized_loss: 0.0784 - val_loss: 0.1965 - val_penalized_loss: 0.1965\n",
      "Epoch 450/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0803 - penalized_loss: 0.0803\n",
      "Epoch 00450: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0450.ckpt\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.0803 - penalized_loss: 0.0803 - val_loss: 0.2113 - val_penalized_loss: 0.2113\n",
      "Epoch 451/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0791 - penalized_loss: 0.0791 - val_loss: 0.2117 - val_penalized_loss: 0.2117\n",
      "Epoch 452/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0768 - penalized_loss: 0.0768 - val_loss: 0.2002 - val_penalized_loss: 0.2002\n",
      "Epoch 453/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0768 - penalized_loss: 0.0768 - val_loss: 0.2753 - val_penalized_loss: 0.2753\n",
      "Epoch 454/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0805 - penalized_loss: 0.0805 - val_loss: 0.2221 - val_penalized_loss: 0.2221\n",
      "Epoch 455/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0798 - penalized_loss: 0.0798 - val_loss: 0.2146 - val_penalized_loss: 0.2146\n",
      "Epoch 456/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0796 - penalized_loss: 0.0796 - val_loss: 0.2040 - val_penalized_loss: 0.2040\n",
      "Epoch 457/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0764 - penalized_loss: 0.0764 - val_loss: 0.2014 - val_penalized_loss: 0.2014\n",
      "Epoch 458/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0741 - penalized_loss: 0.0741 - val_loss: 0.2349 - val_penalized_loss: 0.2349\n",
      "Epoch 459/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0786 - penalized_loss: 0.0786 - val_loss: 0.2872 - val_penalized_loss: 0.2872\n",
      "Epoch 460/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0792 - penalized_loss: 0.0792 - val_loss: 0.1942 - val_penalized_loss: 0.1942\n",
      "Epoch 461/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0777 - penalized_loss: 0.0777 - val_loss: 0.1951 - val_penalized_loss: 0.1951\n",
      "Epoch 462/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0800 - penalized_loss: 0.0800 - val_loss: 0.1917 - val_penalized_loss: 0.1917\n",
      "Epoch 463/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0755 - penalized_loss: 0.0755 - val_loss: 0.3636 - val_penalized_loss: 0.3636\n",
      "Epoch 464/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0748 - penalized_loss: 0.0748 - val_loss: 0.2037 - val_penalized_loss: 0.2037\n",
      "Epoch 465/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0776 - penalized_loss: 0.0776 - val_loss: 0.2076 - val_penalized_loss: 0.2076\n",
      "Epoch 466/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0760 - penalized_loss: 0.0760 - val_loss: 0.2144 - val_penalized_loss: 0.2144\n",
      "Epoch 467/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0774 - penalized_loss: 0.0774 - val_loss: 0.1946 - val_penalized_loss: 0.1946\n",
      "Epoch 468/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0770 - penalized_loss: 0.0770 - val_loss: 0.7501 - val_penalized_loss: 0.7501\n",
      "Epoch 469/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0755 - penalized_loss: 0.0755 - val_loss: 0.2005 - val_penalized_loss: 0.2005\n",
      "Epoch 470/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0769 - penalized_loss: 0.0769 - val_loss: 0.2975 - val_penalized_loss: 0.2975\n",
      "Epoch 471/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0764 - penalized_loss: 0.0764 - val_loss: 0.2121 - val_penalized_loss: 0.2121\n",
      "Epoch 472/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0766 - penalized_loss: 0.0766 - val_loss: 0.1944 - val_penalized_loss: 0.1944\n",
      "Epoch 473/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0773 - penalized_loss: 0.0773 - val_loss: 0.2060 - val_penalized_loss: 0.2060\n",
      "Epoch 474/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0781 - penalized_loss: 0.0781 - val_loss: 0.1947 - val_penalized_loss: 0.1947\n",
      "Epoch 475/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0738 - penalized_loss: 0.0738 - val_loss: 0.1917 - val_penalized_loss: 0.1917\n",
      "Epoch 476/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0769 - penalized_loss: 0.0769 - val_loss: 0.2060 - val_penalized_loss: 0.2060\n",
      "Epoch 477/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0762 - penalized_loss: 0.0762 - val_loss: 0.1921 - val_penalized_loss: 0.1921\n",
      "Epoch 478/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0742 - penalized_loss: 0.0742 - val_loss: 0.1946 - val_penalized_loss: 0.1946\n",
      "Epoch 479/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0747 - penalized_loss: 0.0747 - val_loss: 0.2087 - val_penalized_loss: 0.2087\n",
      "Epoch 480/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.0745 - penalized_loss: 0.0745 - val_loss: 0.2347 - val_penalized_loss: 0.2347\n",
      "Epoch 481/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0744 - penalized_loss: 0.0744 - val_loss: 0.2548 - val_penalized_loss: 0.2548\n",
      "Epoch 482/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0767 - penalized_loss: 0.0767 - val_loss: 0.1970 - val_penalized_loss: 0.1970\n",
      "Epoch 483/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0777 - penalized_loss: 0.0777 - val_loss: 0.2058 - val_penalized_loss: 0.2058\n",
      "Epoch 484/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0746 - penalized_loss: 0.0746 - val_loss: 0.1937 - val_penalized_loss: 0.1937\n",
      "Epoch 485/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0781 - penalized_loss: 0.0781 - val_loss: 0.1919 - val_penalized_loss: 0.1919\n",
      "Epoch 486/1000\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.0743 - penalized_loss: 0.0743 - val_loss: 0.2080 - val_penalized_loss: 0.2080\n",
      "Epoch 487/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0758 - penalized_loss: 0.0758 - val_loss: 0.1901 - val_penalized_loss: 0.1901\n",
      "Epoch 488/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0737 - penalized_loss: 0.0737 - val_loss: 0.1960 - val_penalized_loss: 0.1960\n",
      "Epoch 489/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0764 - penalized_loss: 0.0764 - val_loss: 0.1957 - val_penalized_loss: 0.1957\n",
      "Epoch 490/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0720 - penalized_loss: 0.0720 - val_loss: 0.2868 - val_penalized_loss: 0.2868\n",
      "Epoch 491/1000\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.0772 - penalized_loss: 0.0772 - val_loss: 0.2158 - val_penalized_loss: 0.2158\n",
      "Epoch 492/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0737 - penalized_loss: 0.0737 - val_loss: 0.1943 - val_penalized_loss: 0.1943\n",
      "Epoch 493/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0760 - penalized_loss: 0.0760 - val_loss: 0.1922 - val_penalized_loss: 0.1922\n",
      "Epoch 494/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0755 - penalized_loss: 0.0755 - val_loss: 0.1950 - val_penalized_loss: 0.1950\n",
      "Epoch 495/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0774 - penalized_loss: 0.0774 - val_loss: 0.2419 - val_penalized_loss: 0.2419\n",
      "Epoch 496/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0757 - penalized_loss: 0.0757 - val_loss: 0.1948 - val_penalized_loss: 0.1948\n",
      "Epoch 497/1000\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.0764 - penalized_loss: 0.0764 - val_loss: 7.1114 - val_penalized_loss: 7.1114\n",
      "Epoch 498/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0756 - penalized_loss: 0.0756 - val_loss: 0.3796 - val_penalized_loss: 0.3796\n",
      "Epoch 499/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0755 - penalized_loss: 0.0755 - val_loss: 0.3783 - val_penalized_loss: 0.3783\n",
      "Epoch 500/1000\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.0748 - penalized_loss: 0.0748\n",
      "Epoch 00500: saving model to /home/kvassay/data/z/models/E8/checkpoint/cp-0500.ckpt\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.0749 - penalized_loss: 0.0749 - val_loss: 0.1946 - val_penalized_loss: 0.1946\n",
      "Epoch 501/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0761 - penalized_loss: 0.0761 - val_loss: 0.1952 - val_penalized_loss: 0.1952\n",
      "Epoch 502/1000\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.0767 - penalized_loss: 0.0767 - val_loss: 0.1918 - val_penalized_loss: 0.1918\n",
      "Epoch 503/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0727 - penalized_loss: 0.0727 - val_loss: 0.1962 - val_penalized_loss: 0.1962\n",
      "Epoch 504/1000\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.0723 - penalized_loss: 0.0723 - val_loss: 0.2054 - val_penalized_loss: 0.2054\n",
      "Epoch 505/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0744 - penalized_loss: 0.0744 - val_loss: 0.2244 - val_penalized_loss: 0.2244\n",
      "Epoch 506/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0717 - penalized_loss: 0.0717 - val_loss: 0.1950 - val_penalized_loss: 0.1950\n",
      "Epoch 507/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0755 - penalized_loss: 0.0755 - val_loss: 0.2068 - val_penalized_loss: 0.2068\n",
      "Epoch 508/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.0753 - penalized_loss: 0.0753 - val_loss: 0.2089 - val_penalized_loss: 0.2089\n",
      "Epoch 509/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0721 - penalized_loss: 0.0721 - val_loss: 0.1932 - val_penalized_loss: 0.1932\n",
      "Epoch 510/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0731 - penalized_loss: 0.0731 - val_loss: 0.1968 - val_penalized_loss: 0.1968\n",
      "Epoch 511/1000\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.0741 - penalized_loss: 0.0741 - val_loss: 0.1907 - val_penalized_loss: 0.1907\n",
      "Epoch 512/1000\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0733 - penalized_loss: 0.0733 - val_loss: 0.1929 - val_penalized_loss: 0.1929\n",
      "Epoch 513/1000\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0740 - penalized_loss: 0.0740 - val_loss: 0.1971 - val_penalized_loss: 0.1971\n",
      "Epoch 514/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.0721 - penalized_loss: 0.0721 - val_loss: 0.1935 - val_penalized_loss: 0.1935\n",
      "Epoch 515/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0716 - penalized_loss: 0.0716 - val_loss: 0.1986 - val_penalized_loss: 0.1986\n",
      "Epoch 516/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0703 - penalized_loss: 0.0703 - val_loss: 0.2109 - val_penalized_loss: 0.2109\n",
      "Epoch 517/1000\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.0720 - penalized_loss: 0.0720 - val_loss: 0.3662 - val_penalized_loss: 0.3662\n",
      "Epoch 518/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0733 - penalized_loss: 0.0733 - val_loss: 0.2352 - val_penalized_loss: 0.2352\n",
      "Epoch 519/1000\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.0731 - penalized_loss: 0.0731 - val_loss: 0.3965 - val_penalized_loss: 0.3965\n",
      "Epoch 520/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0701 - penalized_loss: 0.0701 - val_loss: 0.2751 - val_penalized_loss: 0.2751\n",
      "Epoch 521/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0715 - penalized_loss: 0.0715 - val_loss: 0.2363 - val_penalized_loss: 0.2363\n",
      "Epoch 522/1000\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.0713 - penalized_loss: 0.0713 - val_loss: 0.1940 - val_penalized_loss: 0.1940\n",
      "Epoch 523/1000\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.0729 - penalized_loss: 0.0729 - val_loss: 0.1955 - val_penalized_loss: 0.1955\n",
      "Epoch 524/1000\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0734 - penalized_loss: 0.0734 - val_loss: 0.2020 - val_penalized_loss: 0.2020\n",
      "Epoch 525/1000\n",
      "104/200 [==============>...............] - ETA: 4s - loss: 0.0709 - penalized_loss: 0.0709"
     ]
    }
   ],
   "source": [
    "model=experiment(learning_rate=0.02,epochs=1000,batch_size=128,steps=200,name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_SAVE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
