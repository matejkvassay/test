{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu==2.0.0-rc0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of selected best model - LEM-TF-SEQ-E7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.keras as K\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import normalize as scikit_normalize\n",
    "from sklearn.metrics import classification_report\n",
    "from evaluation import rmse_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1_{}.pickle'\n",
    "TYPE='lem_tok'\n",
    "MODEL_FOLDER='/home/kvassay/data/z/models/best_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.98 s, sys: 1.22 s, total: 9.2 s\n",
      "Wall time: 8.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(DATASET.format(TYPE),'rb') as f:\n",
    "    _,_,test_ds=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_loss(y_true, y_pred):\n",
    "    return K.backend.mean(K.backend.square(K.backend.abs(y_true - y_pred))/y_true)\n",
    "\n",
    "\n",
    "class SentimentPredictionModel:\n",
    "    def __init__(self,model_folder):\n",
    "        with open(os.path.join(model_folder, 'vectorizer_summary.pickle'),'rb') as f:\n",
    "            self.vectorizer_summary=pickle.load(f)\n",
    "        with open(os.path.join(model_folder,'vectorizer_text.pickle'), 'rb') as f:\n",
    "            self.vectorizer_text=pickle.load(f)\n",
    "        self.model = K.models.load_model(os.path.join(model_folder,'keras_regressor.h5'),\n",
    "                                          custom_objects={'penalized_loss': penalized_loss})\n",
    "        \n",
    "    @staticmethod\n",
    "    def _tf_predict(vectorizer,dataset,key):\n",
    "        features=vectorizer.transform([' '.join(x[key]) for x in dataset])\n",
    "        return features\n",
    "\n",
    "    def _extract_features(self,dataset,key_summary,key_text):\n",
    "        summ_vecs=self._tf_predict(self.vectorizer_summary,dataset, key_summary)\n",
    "        text_vecs=self._tf_predict(self.vectorizer_text,dataset, key_text)\n",
    "        return scikit_normalize(hstack([summ_vecs, text_vecs],format='csr'))\n",
    "\n",
    "    @staticmethod\n",
    "    def _fix_ratings_over_limit(y_pred,cast_f=float):\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            # fix values over limit (>5, <1)\n",
    "            if y_pred[i]>5:\n",
    "                y_pred[i]=cast_f(5)\n",
    "            if y_pred[i]<1:\n",
    "                y_pred[i]=cast_f(1)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self, dataset_tokenized, key_summary='summary',key_text='text',fix_overlimit=False,\n",
    "                integer=False):\n",
    "        X_pred=self._extract_features(dataset_tokenized,key_summary,key_text)\n",
    "        y_pred=self.model.predict(X_pred.todense())\n",
    "        if integer:\n",
    "            y_pred= np.rint(y_pred)\n",
    "            if fix_overlimit:\n",
    "                y_pred=self._fix_ratings_over_limit(y_pred,cast_f=int)\n",
    "        else:\n",
    "            if fix_overlimit:\n",
    "                y_pred=self._fix_ratings_over_limit(y_pred,cast_f=float)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 596 ms, total: 2.6 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_analyzer=SentimentPredictionModel(MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8527"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=np.array([x['score'] for x in test_ds])\n",
    "y_test_int=np.array([int(x) for x in y_pred])\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 12.2 s, total: 34.6 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_raw=sentiment_analyzer.predict(test_ds,fix_overlimit=False)\n",
    "y_pred_float=sentiment_analyzer.predict(test_ds,fix_overlimit=True)\n",
    "y_pred_int=sentiment_analyzer.predict(test_ds,fix_overlimit=True,integer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) - Raw output RMSE \n",
    "- we calculate RMSE scores from raw outputs of the model\n",
    "- fair for comparison with development set evaluation scores\n",
    "- model generalizes very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2> RMSE report </h2>\n",
       "    <h3> RMSE </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.533</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.646</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    <hr>\n",
       "    <h3> Partial RMSE </h3>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>2.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.414</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>4.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>0.683</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>0.065</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE</td>\n",
       "                <td>0.755</td>\n",
       "            </tr>            \n",
       "        </table>\n",
       "    </div>\n",
       "    <h3> Improvement over baseline (&forall;1.0) </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.887</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>1.317</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>3.245</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    </div>\n",
       "    \n",
       "    <h3> Partial RMSE detailed</h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Review Score</th>\n",
       "                <th>RMSE</th>\n",
       "                <th>RMSE baseline (&forall;1.0)</th>\n",
       "                <th>Improvement over baseline</th>\n",
       "            </tr>\n",
       "            \n",
       "    <tr>\n",
       "        <td>\n",
       "            5.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.625\n",
       "        </td>\n",
       "        <td>\n",
       "            0.0\n",
       "        </td>\n",
       "        <td>\n",
       "            -0.625\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.586\n",
       "        </td>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.414\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.721\n",
       "        </td>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            1.279\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.727\n",
       "        </td>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            2.273\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.755\n",
       "        </td>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            3.245\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "        </table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_report(y_test,y_pred_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) - RMSE scores with overlimit correction\n",
    "- values >5 and <1 will be replaced by 5 or 1\n",
    "- evaluation of score for realistic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2> RMSE report </h2>\n",
       "    <h3> RMSE </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.533</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.617</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    <hr>\n",
       "    <h3> Partial RMSE </h3>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>2.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.414</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>4.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>0.664</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>0.077</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE</td>\n",
       "                <td>0.741</td>\n",
       "            </tr>            \n",
       "        </table>\n",
       "    </div>\n",
       "    <h3> Improvement over baseline (&forall;1.0) </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.916</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>1.336</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>3.259</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    </div>\n",
       "    \n",
       "    <h3> Partial RMSE detailed</h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Review Score</th>\n",
       "                <th>RMSE</th>\n",
       "                <th>RMSE baseline (&forall;1.0)</th>\n",
       "                <th>Improvement over baseline</th>\n",
       "            </tr>\n",
       "            \n",
       "    <tr>\n",
       "        <td>\n",
       "            5.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.588\n",
       "        </td>\n",
       "        <td>\n",
       "            0.0\n",
       "        </td>\n",
       "        <td>\n",
       "            -0.588\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.553\n",
       "        </td>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.447\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.715\n",
       "        </td>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            1.285\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.721\n",
       "        </td>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            2.279\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.741\n",
       "        </td>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            3.259\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "        </table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_report(y_test,y_pred_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) - Evaluation of classification scores\n",
    "- in case we wanted to use this model as Amazon review classifier\n",
    "- not working so well\n",
    "- categories are easy to miss however, except for 1 and 5\n",
    "- possible human agreement also low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.73      0.84       935\n",
      "           2       0.56      0.54      0.55       609\n",
      "           3       0.63      0.43      0.51      1116\n",
      "           4       0.67      0.36      0.46      3670\n",
      "           5       0.48      1.00      0.65      2197\n",
      "\n",
      "    accuracy                           0.59      8527\n",
      "   macro avg       0.67      0.61      0.60      8527\n",
      "weighted avg       0.65      0.59      0.57      8527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_int, y_pred_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) - Evaluation of classification scores - binary problem\n",
    "- let's say we try to classify whether customer was satisfied\n",
    "- score 1/2 => satisfied, score 3/4/6 => not satisfied\n",
    "- sentiment analyser is pretty good at distinguishing between positive/negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bin=np.array([1 if x <3 else 0 for x in y_test])\n",
    "y_pred_bin=np.array([1 if x <3 else 0 for x in y_pred_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      7308\n",
      "           1       0.74      0.93      0.82      1219\n",
      "\n",
      "    accuracy                           0.94      8527\n",
      "   macro avg       0.86      0.94      0.89      8527\n",
      "weighted avg       0.95      0.94      0.95      8527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bin,y_pred_bin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
