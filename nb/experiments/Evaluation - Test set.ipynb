{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu==2.0.0-rc0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of selected best model - LEM-TF-SEQ-E7\n",
    "\n",
    "####  Model notes\n",
    "- achieved best Mean Partial RMSE (0.678) & was able to reach the lowest training loss (0.0261) => higher learning ability compared to other models.\n",
    "- TF-IDF was disabled because analysis shows that frequent word are significant for sentiment analysis(words like great, awful etc.). Also IDF doens't account for imbalance in our dataset.\n",
    "- Model is NN with 1 hidden layer\n",
    "- Model uses concatenated TF vectors of summary and text (two separate vectorization models)\n",
    "- All input texts are expected to be tokenized & lemmatized.\n",
    "- During training balanced undersampling and penalized loss were applied. Penalized loss makes errors in predicting higher ratings less significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.keras as K\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import normalize as scikit_normalize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from evaluation import rmse_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1_{}.pickle'\n",
    "TYPE='lem_tok'\n",
    "MODEL_FOLDER='/home/kvassay/data/z/models/best_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.35 s, sys: 1.14 s, total: 6.48 s\n",
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(DATASET.format(TYPE),'rb') as f:\n",
    "    _,_,test_ds=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_loss(y_true, y_pred):\n",
    "    return K.backend.mean(K.backend.square(K.backend.abs(y_true - y_pred))/y_true)\n",
    "\n",
    "\n",
    "class SentimentPredictionModel:\n",
    "    def __init__(self,model_folder):\n",
    "        with open(os.path.join(model_folder, 'vectorizer_summary.pickle'),'rb') as f:\n",
    "            self.vectorizer_summary=pickle.load(f)\n",
    "        with open(os.path.join(model_folder,'vectorizer_text.pickle'), 'rb') as f:\n",
    "            self.vectorizer_text=pickle.load(f)\n",
    "        self.model = K.models.load_model(os.path.join(model_folder,'keras_regressor.h5'),\n",
    "                                          custom_objects={'penalized_loss': penalized_loss})\n",
    "        \n",
    "    @staticmethod\n",
    "    def _tf_predict(vectorizer,dataset,key):\n",
    "        features=vectorizer.transform([' '.join(x[key]) for x in dataset])\n",
    "        return features\n",
    "\n",
    "    def _extract_features(self,dataset,key_summary,key_text):\n",
    "        summ_vecs=self._tf_predict(self.vectorizer_summary,dataset, key_summary)\n",
    "        text_vecs=self._tf_predict(self.vectorizer_text,dataset, key_text)\n",
    "        return scikit_normalize(hstack([summ_vecs, text_vecs],format='csr'))\n",
    "\n",
    "    @staticmethod\n",
    "    def _fix_ratings_over_limit(y_pred,cast_f=float):\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            # fix values over limit (>5, <1)\n",
    "            if y_pred[i]>5:\n",
    "                y_pred[i]=cast_f(5)\n",
    "            if y_pred[i]<1:\n",
    "                y_pred[i]=cast_f(1)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self, dataset_tokenized, key_summary='summary',key_text='text',fix_overlimit=False,\n",
    "                integer=False):\n",
    "        X_pred=self._extract_features(dataset_tokenized,key_summary,key_text)\n",
    "        y_pred=self.model.predict(X_pred.todense())\n",
    "        if integer:\n",
    "            y_pred= np.rint(y_pred)\n",
    "            if fix_overlimit:\n",
    "                y_pred=self._fix_ratings_over_limit(y_pred,cast_f=int)\n",
    "        else:\n",
    "            if fix_overlimit:\n",
    "                y_pred=self._fix_ratings_over_limit(y_pred,cast_f=float)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 396 ms, total: 2.3 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_analyzer=SentimentPredictionModel(MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8527"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=np.array([x['score'] for x in test_ds])\n",
    "y_test_int=np.array([int(x) for x in y_test])\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 14.1 s, total: 35.7 s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_raw=sentiment_analyzer.predict(test_ds,fix_overlimit=False)\n",
    "y_pred_float=sentiment_analyzer.predict(test_ds,fix_overlimit=True)\n",
    "y_pred_int=sentiment_analyzer.predict(test_ds,fix_overlimit=True,integer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) - Raw output RMSE \n",
    "- we calculate RMSE scores from raw outputs of the model\n",
    "- fair for comparison with development set evaluation scores\n",
    "- model generalizes very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2> RMSE report </h2>\n",
       "    <h3> RMSE </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.533</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.646</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    <hr>\n",
       "    <h3> Partial RMSE </h3>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>2.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.414</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>4.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>0.683</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>0.065</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE</td>\n",
       "                <td>0.755</td>\n",
       "            </tr>            \n",
       "        </table>\n",
       "    </div>\n",
       "    <h3> Improvement over baseline (&forall;1.0) </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.887</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>1.317</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>3.245</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    </div>\n",
       "    \n",
       "    <h3> Partial RMSE detailed</h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Review Score</th>\n",
       "                <th>RMSE</th>\n",
       "                <th>RMSE baseline (&forall;1.0)</th>\n",
       "                <th>Improvement over baseline</th>\n",
       "            </tr>\n",
       "            \n",
       "    <tr>\n",
       "        <td>\n",
       "            5.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.625\n",
       "        </td>\n",
       "        <td>\n",
       "            0.0\n",
       "        </td>\n",
       "        <td>\n",
       "            -0.625\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.586\n",
       "        </td>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.414\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.721\n",
       "        </td>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            1.279\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.727\n",
       "        </td>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            2.273\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.755\n",
       "        </td>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            3.245\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "        </table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_report(y_test,y_pred_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) - RMSE scores with overlimit correction\n",
    "- values >5 and <1 will be replaced by 5 or 1\n",
    "- evaluation of score for realistic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2> RMSE report </h2>\n",
       "    <h3> RMSE </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.533</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.617</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    <hr>\n",
       "    <h3> Partial RMSE </h3>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>2.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.414</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>4.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>0.664</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>0.077</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE</td>\n",
       "                <td>0.741</td>\n",
       "            </tr>            \n",
       "        </table>\n",
       "    </div>\n",
       "    <h3> Improvement over baseline (&forall;1.0) </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.916</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>1.336</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>3.259</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    </div>\n",
       "    \n",
       "    <h3> Partial RMSE detailed</h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Review Score</th>\n",
       "                <th>RMSE</th>\n",
       "                <th>RMSE baseline (&forall;1.0)</th>\n",
       "                <th>Improvement over baseline</th>\n",
       "            </tr>\n",
       "            \n",
       "    <tr>\n",
       "        <td>\n",
       "            5.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.588\n",
       "        </td>\n",
       "        <td>\n",
       "            0.0\n",
       "        </td>\n",
       "        <td>\n",
       "            -0.588\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.553\n",
       "        </td>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.447\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.715\n",
       "        </td>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            1.285\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.721\n",
       "        </td>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            2.279\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.741\n",
       "        </td>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            3.259\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "        </table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_report(y_test,y_pred_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) - Evaluation of classification scores\n",
    "- in case we wanted to use this model as Amazon review classifier\n",
    "- not working so well\n",
    "- close categories are easy to miss however, except for 1 and 5\n",
    "- possibly human agreement also low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.75      0.79       758\n",
      "           2       0.47      0.60      0.53       461\n",
      "           3       0.52      0.62      0.56       635\n",
      "           4       0.44      0.69      0.54      1215\n",
      "           5       0.94      0.79      0.86      5458\n",
      "\n",
      "    accuracy                           0.75      8527\n",
      "   macro avg       0.64      0.69      0.65      8527\n",
      "weighted avg       0.80      0.75      0.77      8527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_int, y_pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 565  142   37   11    3]\n",
      " [  84  277   71   27    2]\n",
      " [  20  107  393   94   21]\n",
      " [   0   21  111  843  240]\n",
      " [  11   37  151  961 4298]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_int,y_pred_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) - Evaluation of classification scores - binary problem\n",
    "- let's say we try to classify whether customer was satisfied\n",
    "- rating 1/2 => satisfied, rating 3/4/5 => not satisfied\n",
    "- sentiment analyser is pretty good at distinguishing between positive/negative\n",
    "- we can see model is better at detecting negative sentiment (possibly caused by sampling/penalized loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bin=np.array([1 if x >3 else 0 for x in y_test])\n",
    "y_pred_bin=np.array([1 if x >3 else 0 for x in y_pred_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82      1854\n",
      "           1       0.93      0.98      0.96      6673\n",
      "\n",
      "    accuracy                           0.93      8527\n",
      "   macro avg       0.92      0.86      0.89      8527\n",
      "weighted avg       0.93      0.93      0.93      8527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bin,y_pred_bin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
