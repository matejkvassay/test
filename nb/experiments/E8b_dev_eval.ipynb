{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import normalize as scikit_normalize\n",
    "from evaluation import plot_history\n",
    "from evaluation import rmse_report\n",
    "from sampling import UnderSampler3D\n",
    "from fasttext_embedding import FastTextEmbeddingBag\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_CHECKPOINT=True\n",
    "MODEL_SAVE_DIR='/home/kvassay/data/z/models/E8/keras_cnn.h5'\n",
    "MODEL_CHECKPOINT_PATH='/home/kvassay/data/z/models/E8/checkpoint/cp-{epoch:04d}.ckpt'\n",
    "\n",
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1_{}.pickle'\n",
    "TYPE='tok'\n",
    "TB_LOG_DIR='/home/kvassay/data/z/log/E8/scalars/'\n",
    "VEC_DIM=100\n",
    "FASTTEXT='/home/kvassay/data/z/models/fasttext/cbow_{}_e{}_w{}.bin'.format(VEC_DIM,50,5)\n",
    "SEQ_PADDING=50\n",
    "CHECKPOINT_DIR='/tmp/z/checkpoint_dim{}_pad{}/'.format(VEC_DIM,SEQ_PADDING)\n",
    "ALLOWED_SPECIAL=tuple(['?','!',':(', ':)', ':D',':-)',':-D',':\\'(',':/',':-/','<3',':-P',':P'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 1.37 s, total: 6.31 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(DATASET.format(TYPE),'rb') as f:\n",
    "    train,dev,_=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    fasttext=FastTextEmbeddingBag(FASTTEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text + extract features\n",
    "- filter out EN stop-words (and, or, ...)\n",
    "- filter out non-allowed special tokens (we want to keep smileys and !,?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_special= re.compile(\"|\".join(re.escape(s) for s in ALLOWED_SPECIAL))\n",
    "\n",
    "def word_filter(word):\n",
    "    if word in STOP_WORDS:\n",
    "        return False\n",
    "    if not word.isalpha():\n",
    "        if not rx_special.findall(word):\n",
    "            return False\n",
    "    else:\n",
    "        if len(word)<3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return [x.lower() for x in text if word_filter(x.lower())]\n",
    "\n",
    "def preprocess_texts(dataset,text_keys=['summary','text']):\n",
    "    for sample in tqdm(dataset):\n",
    "        for key in text_keys:\n",
    "            sample[key]=preprocess_text(sample[key])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 10.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    train=preprocess_texts(train)\n",
    "    dev=preprocess_texts(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "- transform texts to averages of their fastText vectors\n",
    "- concatenate summary & text average vectors into single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_vecs(vecs_mtx,length):\n",
    "    return pad_sequences(vecs_mtx,\n",
    "                         maxlen=length,\n",
    "                         dtype='float32',\n",
    "                        padding='post',\n",
    "                        truncating='post')\n",
    "\n",
    "def extract_features(dataset, fasttext):\n",
    "    default_vec=np.zeros(VEC_DIM,dtype=np.float32)\n",
    "    vecs_all=[]\n",
    "    for sample in tqdm(dataset):\n",
    "        all_words=sample['summary']+sample['text']\n",
    "        if all_words:\n",
    "            vecs=fasttext.forward([x for x in all_words])\n",
    "        else:\n",
    "            vecs=np.array([default_vec])\n",
    "        vecs=scikit_normalize(vecs)\n",
    "        vecs=vecs.reshape(1,vecs.shape[0],vecs.shape[1])         \n",
    "        vecs = pad_vecs(vecs, SEQ_PADDING)\n",
    "        vecs_all.append(vecs)\n",
    "    vecs_all=np.array(vecs_all)\n",
    "    vecs_all=vecs_all.reshape(vecs_all.shape[0],vecs_all.shape[2],vecs_all.shape[3])\n",
    "    return vecs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    with open(CHECKPOINT_DIR+'X_train.npy','rb') as f:\n",
    "        X_train=np.load(f)\n",
    "    with open(CHECKPOINT_DIR+'X_dev.npy','rb') as f:\n",
    "        X_dev=np.load(f)\n",
    "    with open(CHECKPOINT_DIR+'y_train.npy','rb') as f:\n",
    "        y_train=np.load(f)\n",
    "    with open(CHECKPOINT_DIR+'y_dev.npy','rb') as f:\n",
    "        y_dev=np.load(f)\n",
    "    return X_train,X_dev,y_train,y_dev\n",
    "        \n",
    "def checkpoint(X_train,X_dev,y_train,y_dev):\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        os.makedirs(CHECKPOINT_DIR)\n",
    "    with open(CHECKPOINT_DIR+'X_train.npy','wb') as f:\n",
    "        np.save(f,X_train)\n",
    "    with open(CHECKPOINT_DIR+'X_dev.npy','wb') as f:\n",
    "        np.save(f,X_dev)\n",
    "    with open(CHECKPOINT_DIR+'y_train.npy','wb') as f:\n",
    "        np.save(f,y_train)\n",
    "    with open(CHECKPOINT_DIR+'y_dev.npy','wb') as f:\n",
    "        np.save(f,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 258 ms, sys: 9.56 s, total: 9.82 s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    X_train=extract_features(train,fasttext)\n",
    "    X_dev=extract_features(dev,fasttext)\n",
    "    y_train=np.array([x['score'] for x in train])\n",
    "    y_dev=np.array([x['score'] for x in dev])\n",
    "    print('Train samples shape: {}, Dev samples shape: {}'.format(X_train.shape,X_dev.shape))\n",
    "else:\n",
    "    X_train,X_dev,y_train,y_dev=load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not FROM_CHECKPOINT:\n",
    "    checkpoint(X_train,X_dev,y_train,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_loss(y_true, y_pred):\n",
    "    return K.backend.mean(K.backend.square(K.backend.abs(y_true - y_pred))/y_true)\n",
    "\n",
    "def experiment():\n",
    "    model=K.models.load_model(MODEL_SAVE_DIR\n",
    "                              ,custom_objects={'penalized_loss': penalized_loss})\n",
    "    y_pred_dev=model.predict(X_dev)\n",
    "    rmse_report(y_dev,y_pred_dev,title='RMSE report')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2> RMSE report </h2>\n",
       "    <h3> RMSE </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.53</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.763</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    <hr>\n",
       "    <h3> Partial RMSE </h3>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>2.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>1.414</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE (baseline &forall;1.0)</td>\n",
       "                <td>4.0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>0.796</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>0.101</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>St.dev. partial RMSE</td>\n",
       "                <td>0.93</td>\n",
       "            </tr>            \n",
       "        </table>\n",
       "    </div>\n",
       "    <h3> Improvement over baseline (&forall;1.0) </h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td>RMSE</td>\n",
       "                <td>0.767</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Mean partial RMSE</td>\n",
       "                <td><b>1.204</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td>Max partial RMSE</td>\n",
       "                <td>3.07</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "    </div>\n",
       "    \n",
       "    <h3> Partial RMSE detailed</h3>\n",
       "    <hr>\n",
       "    <div>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Review Score</th>\n",
       "                <th>RMSE</th>\n",
       "                <th>RMSE baseline (&forall;1.0)</th>\n",
       "                <th>Improvement over baseline</th>\n",
       "            </tr>\n",
       "            \n",
       "    <tr>\n",
       "        <td>\n",
       "            5.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.75\n",
       "        </td>\n",
       "        <td>\n",
       "            0.0\n",
       "        </td>\n",
       "        <td>\n",
       "            -0.75\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.664\n",
       "        </td>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.336\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.741\n",
       "        </td>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            1.259\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            2.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.93\n",
       "        </td>\n",
       "        <td>\n",
       "            3.0\n",
       "        </td>\n",
       "        <td>\n",
       "            2.07\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "\n",
       "    <tr>\n",
       "        <td>\n",
       "            1.0\n",
       "        </td>\n",
       "        <td>\n",
       "            0.896\n",
       "        </td>\n",
       "        <td>\n",
       "            4.0\n",
       "        </td>\n",
       "        <td>\n",
       "            3.104\n",
       "        </td>\n",
       "    </tr>\n",
       "    \n",
       "        </table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 25, 256)           77056     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 539,905\n",
      "Trainable params: 538,369\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
