{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE='/home/kvassay/data/z/models/sentencepiece/sp_lc_{}' \n",
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1.pickle'\n",
    "TMP_DATASET_FILE='/tmp/spt_train.txt'\n",
    "VOCAB_SIZES=[8000,16000,32000,64000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET,'rb') as f:\n",
    "    train,dev,_=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_file(dataset, save_path, limit_data=None):\n",
    "    with open(TMP_DATASET_FILE, 'w') as f:\n",
    "        if limit_data is None:\n",
    "            limit=10000000000\n",
    "        else:\n",
    "            limit=limit_data\n",
    "        f.writelines([x['text'].lower()+'\\n' for x in dataset if x][:limit])\n",
    "        \n",
    "def train_sentpiece(dataset_path, vocab_size, save_path):\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '--input={} --model_prefix={} --vocab_size={}'.format(\n",
    "            dataset_path,\n",
    "            save_path,\n",
    "            vocab_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_file(train,TMP_DATASET_FILE, limit_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 8000 tokens model took 169.7974009513855 seconds.\n",
      "Training 16000 tokens model took 159.92341208457947 seconds.\n",
      "Training 32000 tokens model took 156.61435079574585 seconds.\n",
      "Training 64000 tokens model took 153.4472267627716 seconds.\n"
     ]
    }
   ],
   "source": [
    "for vocab_size in VOCAB_SIZES:\n",
    "    start=time()\n",
    "    train_sentpiece(TMP_DATASET_FILE, vocab_size, MODEL_SAVE.format(vocab_size))\n",
    "    end=time()\n",
    "    print('Training {} tokens model took {} seconds.'.format(vocab_size,end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model='/home/kvassay/data/z/models/sentencepiece/sp_lc_64000.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=1951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My dog eats Nature\\'s Recipe \"Easy to Digest\" dry food everyday. It really helped with her digestive issues. I thought the wet food version would be okay, but it made me completely ill. She was dry-heaving, had major gas issues and was quite lethargic. About 12 hours after her final dose of it, all of her symptoms disappeared. The dry food is still great, but this wet food is really awful.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[ID]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁my',\n",
       " '▁dog',\n",
       " '▁eats',\n",
       " '▁nature',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁recipe',\n",
       " '▁\"',\n",
       " 'easy',\n",
       " '▁to',\n",
       " '▁digest',\n",
       " '\"',\n",
       " '▁dry',\n",
       " '▁food',\n",
       " '▁everyday',\n",
       " '.',\n",
       " '▁it',\n",
       " '▁really',\n",
       " '▁helped',\n",
       " '▁with',\n",
       " '▁her',\n",
       " '▁digestive',\n",
       " '▁issues',\n",
       " '.',\n",
       " '▁i',\n",
       " '▁thought',\n",
       " '▁the',\n",
       " '▁wet',\n",
       " '▁food',\n",
       " '▁version',\n",
       " '▁would',\n",
       " '▁be',\n",
       " '▁okay',\n",
       " ',',\n",
       " '▁but',\n",
       " '▁it',\n",
       " '▁made',\n",
       " '▁me',\n",
       " '▁completely',\n",
       " '▁i',\n",
       " 'll',\n",
       " '.',\n",
       " '▁she',\n",
       " '▁was',\n",
       " '▁dry',\n",
       " '-',\n",
       " 'he',\n",
       " 'aving',\n",
       " ',',\n",
       " '▁had',\n",
       " '▁major',\n",
       " '▁gas',\n",
       " '▁issues',\n",
       " '▁and',\n",
       " '▁was',\n",
       " '▁quite',\n",
       " '▁lethargic',\n",
       " '.',\n",
       " '▁about',\n",
       " '▁12',\n",
       " '▁hours',\n",
       " '▁after',\n",
       " '▁her',\n",
       " '▁final',\n",
       " '▁dose',\n",
       " '▁of',\n",
       " '▁it',\n",
       " ',',\n",
       " '▁all',\n",
       " '▁of',\n",
       " '▁her',\n",
       " '▁symptoms',\n",
       " '▁disappeared',\n",
       " '.',\n",
       " '▁the',\n",
       " '▁dry',\n",
       " '▁food',\n",
       " '▁is',\n",
       " '▁still',\n",
       " '▁great',\n",
       " ',',\n",
       " '▁but',\n",
       " '▁this',\n",
       " '▁wet',\n",
       " '▁food',\n",
       " '▁is',\n",
       " '▁really',\n",
       " '▁awful',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.EncodeAsPieces(dev[ID]['text'].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My dog eats Nature\\'s Recipe \"Easy to Digest\" dry food everyday. It really helped with her digestive issues. I thought the wet food version would be okay, but it made me completely ill. She was dry-heaving, had major gas issues and was quite lethargic. About 12 hours after her final dose of it, all of her symptoms disappeared. The dry food is still great, but this wet food is really awful.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.DecodePieces(tokenizer.EncodeAsPieces(dev[ID]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
