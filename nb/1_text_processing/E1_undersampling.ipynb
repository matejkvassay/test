{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip imbalanced-learn\n",
    "#!pip install tensorflow-gpu==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize as scikit_normalize\n",
    "from sklearn.utils import shuffle as  sklearn_shuffle\n",
    "\n",
    "from IPython.core.display import display\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1_{}.pickle'\n",
    "TYPE='tok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 1.15 s, total: 5.81 s\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(DATASET.format(TYPE),'rb') as f:\n",
    "    train,dev,test=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train TF vectorizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_train(dataset,key, **scikit_kwargs):\n",
    "    vectorizer=TfidfVectorizer(**scikit_kwargs)\n",
    "    vectorizer.fit([' '.join(x[key]) for x in dataset])\n",
    "    return vectorizer\n",
    "\n",
    "def tf_predict(vectorizer,dataset,key, apply_norm=True):\n",
    "    features=vectorizer.transform([' '.join(x[key]) for x in dataset])\n",
    "    if apply_norm is True:\n",
    "        features=scikit_normalize(features)\n",
    "    return features\n",
    "\n",
    "def extract_features(dataset,vectorizer_summary,vectorizer_text):\n",
    "    summ_vecs=tf_predict(vectorizer_summary,dataset,'summary')\n",
    "    text_vecs=tf_predict(vectorizer_text,dataset,'text')\n",
    "    return hstack([summ_vecs, text_vecs],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer_text=tf_train(train,'text',max_features=35000,ngram_range=(1,2),max_df=0.99,lowercase=True,use_idf=False)\n",
    "vectorizer_summary=tf_train(train,'summary',max_features=5000,ngram_range=(1,2),max_df=0.99,lowercase=True,use_idf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples shape: (551399, 40000), Dev samples shape: (8527, 40000)\n",
      "CPU times: user 57.2 s, sys: 1.24 s, total: 58.5 s\n",
      "Wall time: 58.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train=extract_features(train, vectorizer_summary,vectorizer_text)\n",
    "X_dev=extract_features(dev, vectorizer_summary,vectorizer_text)\n",
    "y_train=np.array([x['score'] for x in train])\n",
    "y_dev=np.array([x['score'] for x in dev])\n",
    "print('Train samples shape: {}, Dev samples shape: {}'.format(X_train.shape,X_dev.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderSampler(K.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.rus=RandomUnderSampler(sampling_strategy='not minority')\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size = batch_size\n",
    "        #len\n",
    "        self._shuffle()\n",
    "        self.length= math.ceil(self.X_u.shape[0] / self.batch_size)\n",
    "\n",
    "    def _shuffle(self):\n",
    "        self.X_u, self.y_u=self.rus.fit_resample(self.X,self.y)\n",
    "        self.X_u,self.y_u = sklearn_shuffle(self.X_u,self.y_u)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.X_u[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y_u[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x.todense(), batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._shuffle()\n",
    "        \n",
    "class RandomSampler(K.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size = batch_size\n",
    "        self.sampling_size=np.min([x for (_,x) in dict(Counter(y)).items()])*len(set(y))\n",
    "        #len\n",
    "        self._shuffle()\n",
    "        self.length= math.ceil(self.X_u.shape[0] / self.batch_size)\n",
    "\n",
    "    def _shuffle(self):\n",
    "        self.X_u,_,self.y_u,_=train_test_split(self.X,self.y,shuffle=True,train_size=self.sampling_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.X_u[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y_u[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x.todense(),batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_size=100, epochs=5, sampler_cls=UnderSampler):\n",
    "    model = K.models.Sequential([\n",
    "        K.layers.Dense(100,activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        K.layers.Dense(1,activation='linear'),\n",
    "        K.layers.Activation('linear'),\n",
    "    ])\n",
    "    opt=K.optimizers.Adam(lr=0.02, amsgrad=True)\n",
    "    model.compile(optimizer=opt,loss='mean_squared_error')\n",
    "    sampler=sampler_cls(X_train,y_train,batch_size=batch_size)\n",
    "    model.fit_generator(sampler, shuffle=False, epochs=epochs, validation_data=(X_dev.todense(),y_dev))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model,title):\n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, color='red', label='MSE Train')\n",
    "    plt.plot(epochs, val_loss, color='green', label='MSE Dev')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_history_double(history1, history2, name1, name2, title):\n",
    "    loss1 = history1.history['loss']\n",
    "    val_loss1 = history1.history['val_loss']\n",
    "    epochs1 = range(1, len(loss1) + 1)\n",
    "    loss2 = history2.history['loss']\n",
    "    val_loss2 = history2.history['val_loss']\n",
    "    epochs2 = range(1, len(loss1) + 1)\n",
    "    plt.plot(epochs1, loss1, color='red', label='{}: MSE Train'.format(name1))\n",
    "    plt.plot(epochs1, val_loss1, color='orange', label='{}: MSE Dev'.format(name1))\n",
    "    plt.plot(epochs2, loss2, color='blue', label='{}: MSE Train'.format(name2))\n",
    "    plt.plot(epochs2, val_loss2, color='green', label='{}: MSE Dev'.format(name2))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def rmse(y_true,y_pred):\n",
    "    return sqrt(mean_squared_error(y_true,y_pred))\n",
    "\n",
    "def rmse_partial_avg(y_true, y_pred):\n",
    "    rmse_dict=rmse_partial(y_true,y_pred)\n",
    "    values=list(rmse_dict.values())\n",
    "    return np.mean(values), np.std(values)\n",
    "\n",
    "def rmse_partial_max(y_true, y_pred):\n",
    "    rmse_dict=rmse_partial(y_true,y_pred)\n",
    "    values=list(rmse_dict.values())\n",
    "    return np.max(values)\n",
    "\n",
    "def rmse_partial(y_true, y_pred):\n",
    "    all_scores=list(set(y_true))\n",
    "    y_true_dict={x:[] for x in all_scores}\n",
    "    y_pred_dict={x:[] for x in all_scores}\n",
    "    for i, score in enumerate(y_true):\n",
    "        y_true_dict[score].append(score)\n",
    "        y_pred_dict[score].append(y_pred[i])\n",
    "    return {score: rmse(y_true_dict[score],y_pred_dict[score]) for score in all_scores}\n",
    "\n",
    "def rmse_report(y_true,y_pred,round_decimals=3, title='RMSE report'):\n",
    "    def ar(x):\n",
    "        return np.around(x,decimals=round_decimals)\n",
    "    baseline=rmse(y_true,[5.0]*len(y_true))\n",
    "    HTML_TEMPLATE=\"\"\"\n",
    "    <h2> {} </h2>\n",
    "    <h3> RMSE </h3>\n",
    "    <hr>\n",
    "    <div>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td>RMSE (baseline &forall;1.0)</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>RMSE</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    <hr>\n",
    "    <h3> Partial RMSE </h3>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td>Mean partial RMSE (baseline &forall;1.0)</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Max partial RMSE (baseline &forall;1.0)</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>St.dev. partial RMSE (baseline &forall;1.0)</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Mean partial RMSE</td>\n",
    "                <td><b>{}</b></td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Max partial RMSE</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>St.dev. partial RMSE</td>\n",
    "                <td>{}</td>\n",
    "            </tr>            \n",
    "        </table>\n",
    "    </div>\n",
    "    <h3> Improvement over baseline (&forall;1.0) </h3>\n",
    "    <hr>\n",
    "    <div>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td>RMSE</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Mean partial RMSE</td>\n",
    "                <td><b>{}</b></td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Max partial RMSE</td>\n",
    "                <td>{}</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "    <h3> Partial RMSE detailed</h3>\n",
    "    <hr>\n",
    "    <div>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Review Score</th>\n",
    "                <th>RMSE</th>\n",
    "                <th>RMSE baseline (&forall;1.0)</th>\n",
    "                <th>Improvement over baseline</th>\n",
    "            </tr>\n",
    "            {}\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    PARTIAL_ROW_TEMPLATE='''\n",
    "    <tr>\n",
    "        <td>\n",
    "            {}\n",
    "        </td>\n",
    "        <td>\n",
    "            {}\n",
    "        </td>\n",
    "        <td>\n",
    "            {}\n",
    "        </td>\n",
    "        <td>\n",
    "            {}\n",
    "        </td>\n",
    "    </tr>\n",
    "    '''\n",
    "    overall=rmse(y_true,y_pred)\n",
    "    partial_avg,partial_std=rmse_partial_avg(y_true,y_pred)\n",
    "    partial_max=rmse_partial_max(y_true,y_pred)\n",
    "    partial_avg_baseline,partial_std_baseline=rmse_partial_avg(y_true,[5.0]*len(y_true))\n",
    "    partial_max_baseline=rmse_partial_max(y_true,[5.0]*len(y_true))\n",
    "    improvement_marmse=partial_avg_baseline-partial_avg\n",
    "    improvement_rmse=baseline-overall\n",
    "    improvement_rmse_partial_max=partial_max_baseline - partial_max\n",
    "    \n",
    "    #partial rows\n",
    "    partial=rmse_partial(y_true,y_pred)\n",
    "    partial_baseline=rmse_partial(y_true, [5.0]*len(y_true))\n",
    "    partial=sorted(partial.items(),key=lambda x:x[0],reverse=True)\n",
    "    partial_table_rows=[]\n",
    "    for key,value in partial:\n",
    "        value_baseline=partial_baseline[key]\n",
    "        diff_baseline=value_baseline-value\n",
    "        partial_table_rows.append(PARTIAL_ROW_TEMPLATE.format(key,ar(value),ar(value_baseline),ar(diff_baseline)))\n",
    "    partial_table_rows='\\n'.join(partial_table_rows)\n",
    "    \n",
    "    html=HTML_TEMPLATE.format(title,\n",
    "                              ar(baseline),\n",
    "                              ar(overall),\n",
    "                              ar(partial_avg_baseline),\n",
    "                              ar(partial_std_baseline),\n",
    "                              ar(partial_max_baseline),\n",
    "                              ar(partial_avg),\n",
    "                              ar(partial_std),\n",
    "                              ar(partial_max),\n",
    "                              ar(improvement_rmse),\n",
    "                              ar(improvement_marmse),\n",
    "                              ar(improvement_rmse_partial_max),\n",
    "                              partial_table_rows)\n",
    "    display(HTML(html))\n",
    "\n",
    "def experiment(sampling_cls,epochs,batch_size,name):\n",
    "    model=train_model(sampler_cls=sampling_cls,epochs=epochs,batch_size=batch_size)\n",
    "    y_pred_dev=model.predict(X_dev)\n",
    "    rmse_report(y_dev,y_pred_dev,title='{} - RMSE report'.format(name))\n",
    "    plot_history(model,title='{} - Train/Dev MSE'.format(name))\n",
    "    return model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 40s 276ms/step - loss: 1.1603 - val_loss: 0.6343\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TypeError while preparing batch. If using HDF5 input data, pass shuffle=\"batch\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/main/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/main/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/main/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'coo_matrix' object is not subscriptable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-527facc757f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomSampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Random sampling'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-866baa132314>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(sampling_cls, epochs, batch_size, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0my_pred_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mrmse_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{} - RMSE report'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{} - Train/Dev MSE'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/main/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/main/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m           raise TypeError('TypeError while preparing batch. '\n\u001b[0m\u001b[1;32m    349\u001b[0m                           \u001b[0;34m'If using HDF5 input data, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                           'pass shuffle=\"batch\".')\n",
      "\u001b[0;31mTypeError\u001b[0m: TypeError while preparing batch. If using HDF5 input data, pass shuffle=\"batch\"."
     ]
    }
   ],
   "source": [
    "history1=experiment(sampling_cls=RandomSampler,epochs=1,batch_size=1000,name='Random sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2=experiment(sampling_cls=UnderSampler,epochs=5,batch_size=1000,name='Under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_double(history1, history2, 'Random sampled','Under-sampled', 'Training curves comparison: Random vs Under-sampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "- under-sampling strategy underperformes in terms of RMSE\n",
    "- under-sampling strategy outperforms in terms of partial RMSE\n",
    "\n",
    "=> strategy helps to deal with label imbalance and pushes RMSE for rare categories lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
