{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE='/Users/matejkvassay/data/sz/models/sentencepiece/sp_lc_{}' \n",
    "DATASET='/Users/matejkvassay/data/sz/data/reviews_train_test_dev1.pickle'\n",
    "TMP_DATASET_FILE='/tmp/spt_train.txt'\n",
    "VOCAB_SIZES=[1000,8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET,'rb') as f:\n",
    "    train,dev,_=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_file(dataset, save_path, limit_data=None):\n",
    "    with open(TMP_DATASET_FILE, 'w') as f:\n",
    "        if limit_data is None:\n",
    "            limit=10000000000\n",
    "        else:\n",
    "            limit=limit_data\n",
    "        f.writelines([x['text'].lower()+'\\n' for x in dataset if x][:limit])\n",
    "        \n",
    "def train_sentpiece(dataset_path, vocab_size, save_path):\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '--input={} --model_prefix={} --vocab_size={}'.format(\n",
    "            dataset_path,\n",
    "            save_path,\n",
    "            vocab_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_file(train,TMP_DATASET_FILE, limit_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1000 tokens model took 287.24037885665894 seconds.\n",
      "Training 8000 tokens model took 235.29969000816345 seconds.\n"
     ]
    }
   ],
   "source": [
    "for vocab_size in VOCAB_SIZES:\n",
    "    start=time()\n",
    "    train_sentpiece(TMP_DATASET_FILE, vocab_size, MODEL_SAVE.format(vocab_size))\n",
    "    end=time()\n",
    "    print('Training {} tokens model took {} seconds.'.format(vocab_size,end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model='/Users/matejkvassay/data/sz/models/sentencepiece/sp_8000.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=1151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I got this for my wife. She likes to cook Pamelas mixes with molasses. It must be good because she eats it all the time. The price was awesome.\\n\\n\\n\\nTwo antlers up.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[ID]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁i',\n",
       " '▁got',\n",
       " '▁this',\n",
       " '▁for',\n",
       " '▁my',\n",
       " '▁wife',\n",
       " '.',\n",
       " '▁she',\n",
       " '▁likes',\n",
       " '▁to',\n",
       " '▁cook',\n",
       " '▁pa',\n",
       " 'me',\n",
       " 'la',\n",
       " 's',\n",
       " '▁mixes',\n",
       " '▁with',\n",
       " '▁molasses',\n",
       " '.',\n",
       " '▁it',\n",
       " '▁must',\n",
       " '▁be',\n",
       " '▁good',\n",
       " '▁because',\n",
       " '▁she',\n",
       " '▁eats',\n",
       " '▁it',\n",
       " '▁all',\n",
       " '▁the',\n",
       " '▁time',\n",
       " '.',\n",
       " '▁the',\n",
       " '▁price',\n",
       " '▁was',\n",
       " '▁awesome',\n",
       " '.',\n",
       " '▁two',\n",
       " '▁antler',\n",
       " 's',\n",
       " '▁up',\n",
       " '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.EncodeAsPieces(dev[ID]['text'].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I got this for my wife. She likes to cook Pamelas mixes with molasses. It must be good because she eats it all the time. The price was awesome. Two antlers up.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.DecodePieces(tokenizer.EncodeAsPieces(dev[ID]['text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
