{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE='/Users/matejkvassay/data/sz/models/sentencepiece/sp_enwiki_lc_{}' \n",
    "DATASET='/Users/matejkvassay/data/sz/data/reviews_train_test_dev1.pickle'\n",
    "TMP_DATASET_FILE='/tmp/spt_train.txt'\n",
    "VOCAB_SIZES=[1000,8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET,'rb') as f:\n",
    "    train,dev,_=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_file(dataset, save_path, limit_data=None):\n",
    "    with open(TMP_DATASET_FILE, 'w') as f:\n",
    "        if limit_data is None:\n",
    "            limit=10000000000\n",
    "        else:\n",
    "            limit=limit_data\n",
    "        f.writelines([x['text'].lower()+'\\n' for x in dataset if x][:limit])\n",
    "        \n",
    "def train_sentpiece(dataset_path, vocab_size, save_path):\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '--input={} --model_prefix={} --vocab_size={}'.format(\n",
    "            dataset_path,\n",
    "            save_path,\n",
    "            vocab_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_file(train,TMP_DATASET_FILE, limit_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1000 tokens model took 287.24037885665894 seconds.\n",
      "Training 8000 tokens model took 235.29969000816345 seconds.\n"
     ]
    }
   ],
   "source": [
    "for vocab_size in VOCAB_SIZES:\n",
    "    start=time()\n",
    "    train_sentpiece(TMP_DATASET_FILE, vocab_size, MODEL_SAVE.format(vocab_size))\n",
    "    end=time()\n",
    "    print('Training {} tokens model took {} seconds.'.format(vocab_size,end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model='/Users/matejkvassay/data/sz/models/sentencepiece/sp_8000.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'howdy y\\'all,\\n\\n\\n\\nthis is GOOD stuff! it\\'s a tad too hot for me, so i either buy the \"milder\" version or add some non-spicy canned tomatoes to it.\\n\\n\\n\\nthe price is ... outrageous, tho. at about twenty-nine dollars for a 12-pack, it comes to nearly two fifty for ONE CAN. since it\\'s listed at ro-tel for a suggested price of one thirty - and available at most grocery stores for one dollar - that\\'s far, far too much.\\n\\n\\n\\nhopefully, the price will eventually drop. then i\\'ll buy LOTS of it! [*grin*]\\n\\n\\n\\ntake care,\\n\\nlee'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[ID]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁how',\n",
       " 'dy',\n",
       " '▁',\n",
       " 'y',\n",
       " \"'\",\n",
       " 'all',\n",
       " ',',\n",
       " '▁this',\n",
       " '▁is',\n",
       " '▁good',\n",
       " '▁stuff',\n",
       " '!',\n",
       " '▁it',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁a',\n",
       " '▁tad',\n",
       " '▁too',\n",
       " '▁hot',\n",
       " '▁for',\n",
       " '▁me',\n",
       " ',',\n",
       " '▁so',\n",
       " '▁i',\n",
       " '▁either',\n",
       " '▁buy',\n",
       " '▁the',\n",
       " '▁\"',\n",
       " 'm',\n",
       " 'il',\n",
       " 'der',\n",
       " '\"',\n",
       " '▁version',\n",
       " '▁or',\n",
       " '▁add',\n",
       " '▁some',\n",
       " '▁non',\n",
       " '-',\n",
       " 'spicy',\n",
       " '▁canned',\n",
       " '▁tomatoes',\n",
       " '▁to',\n",
       " '▁it',\n",
       " '.',\n",
       " '▁the',\n",
       " '▁price',\n",
       " '▁is',\n",
       " '▁...',\n",
       " '▁outrageous',\n",
       " ',',\n",
       " '▁tho',\n",
       " '.',\n",
       " '▁at',\n",
       " '▁about',\n",
       " '▁twenty',\n",
       " '-',\n",
       " 'n',\n",
       " 'ine',\n",
       " '▁dollars',\n",
       " '▁for',\n",
       " '▁a',\n",
       " '▁12-',\n",
       " 'pack',\n",
       " ',',\n",
       " '▁it',\n",
       " '▁comes',\n",
       " '▁to',\n",
       " '▁nearly',\n",
       " '▁two',\n",
       " '▁fifty',\n",
       " '▁for',\n",
       " '▁one',\n",
       " '▁can',\n",
       " '.',\n",
       " '▁since',\n",
       " '▁it',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁listed',\n",
       " '▁at',\n",
       " '▁ro',\n",
       " '-',\n",
       " 't',\n",
       " 'el',\n",
       " '▁for',\n",
       " '▁a',\n",
       " '▁suggested',\n",
       " '▁price',\n",
       " '▁of',\n",
       " '▁one',\n",
       " '▁thirty',\n",
       " '▁-',\n",
       " '▁and',\n",
       " '▁available',\n",
       " '▁at',\n",
       " '▁most',\n",
       " '▁grocery',\n",
       " '▁stores',\n",
       " '▁for',\n",
       " '▁one',\n",
       " '▁dollar',\n",
       " '▁-',\n",
       " '▁that',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁far',\n",
       " ',',\n",
       " '▁far',\n",
       " '▁too',\n",
       " '▁much',\n",
       " '.',\n",
       " '▁hopefully',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁price',\n",
       " '▁will',\n",
       " '▁eventually',\n",
       " '▁drop',\n",
       " '.',\n",
       " '▁then',\n",
       " '▁i',\n",
       " \"'\",\n",
       " 'll',\n",
       " '▁buy',\n",
       " '▁lots',\n",
       " '▁of',\n",
       " '▁it',\n",
       " '!',\n",
       " '▁',\n",
       " '[',\n",
       " '*',\n",
       " 'gr',\n",
       " 'in',\n",
       " '*',\n",
       " ']',\n",
       " '▁take',\n",
       " '▁care',\n",
       " ',',\n",
       " '▁le',\n",
       " 'e']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.EncodeAsPieces(dev[ID]['text'].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'howdy y\\'all, this is GOOD stuff! it\\'s a tad too hot for me, so i either buy the \"milder\" version or add some non-spicy canned tomatoes to it. the price is ... outrageous, tho. at about twenty-nine dollars for a 12-pack, it comes to nearly two fifty for ONE CAN. since it\\'s listed at ro-tel for a suggested price of one thirty - and available at most grocery stores for one dollar - that\\'s far, far too much. hopefully, the price will eventually drop. then i\\'ll buy LOTS of it! [*grin*] take care, lee'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.DecodePieces(tokenizer.EncodeAsPieces(dev[ID]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
