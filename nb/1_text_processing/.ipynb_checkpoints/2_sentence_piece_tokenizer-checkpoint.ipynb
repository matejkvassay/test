{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE='/home/kvassay/data/z/models/sentencepiece/sp_{}' \n",
    "DATASET='/home/kvassay/data/z/data/reviews_train_test_dev1.pickle'\n",
    "TMP_DATASET_FILE='/tmp/spt_train.txt'\n",
    "VOCAB_SIZES=[100,500,1000,8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET,'rb') as f:\n",
    "    train,dev,_=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_file(dataset, save_path, limit_data=None):\n",
    "    with open(TMP_DATASET_FILE, 'w') as f:\n",
    "        if limit_data is None:\n",
    "            limit=10000000000\n",
    "        else:\n",
    "            limit=limit_data\n",
    "        f.writelines([x['text']+'\\n' for x in dataset if x][:limit])\n",
    "        \n",
    "def train_sentpiece(dataset_path, vocab_size, save_path):\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '--input={} --model_prefix={} --vocab_size={}'.format(\n",
    "            dataset_path,\n",
    "            save_path,\n",
    "            vocab_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_file(train,TMP_DATASET_FILE, limit_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 100 tokens model took 188.0792109966278 seconds.\n",
      "Training 500 tokens model took 179.54791069030762 seconds.\n",
      "Training 1000 tokens model took 177.5086886882782 seconds.\n",
      "Training 8000 tokens model took 169.26805591583252 seconds.\n"
     ]
    }
   ],
   "source": [
    "for vocab_size in VOCAB_SIZES:\n",
    "    start=time()\n",
    "    train_sentpiece(TMP_DATASET_FILE, vocab_size, MODEL_SAVE.format(vocab_size))\n",
    "    end=time()\n",
    "    print('Training {} tokens model took {} seconds.'.format(vocab_size,end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model='/home/kvassay/data/z/models/sentencepiece/sp_500.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=1125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First off, I just have to say that this was a large bag of dog food, so if you\\'ve got a smaller dog or a canine friend with a smaller appetite, this bag will go a long way. Also, be careful when carrying this, as the top of this is resealable (yay!) with a ziplock top and this could scratch your neck if you\\'re not a little wary. (Just saying this because I ended up with a long scratch down my neck from carrying this on my shoulder and wanted others to avoid the same fate.)\\n\\n\\n\\nMy friend\\'s canine is a little picky about what he eats, with dry dog food being his \"last resort\". I figured that if I could get this dog to eat and even remotely enjoy this food, then it would be a pretty good recommendation. Now while he didn\\'t take to the Beneful like a fish to water or a cat to milk, he did eat it, which says quite a bit considering how he can be about food.\\n\\n\\n\\nI don\\'t think that Beneful will become a regular addition to the dog\\'s diet but that he eats this means that my friend will have another brand of dogfood that he can guarantee that his dog will nom on. This dog food is a little on the expensive side in the stores in my area and while I can\\'t guarantee what the prices will be in your neck of the woods (Amazon price not withstanding since that can change rapidly sometimes), you might want to do a little pricechecking on various different dogfoods. Beneful is definitely healthier than store brand dog food, but if you\\'re going to spend the money then there\\'s some better stuff out there that\\'s a little more organic and natural.  Castor & Pollux has a slightly higher protein value, for example.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[ID]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁F',\n",
       " 'ir',\n",
       " 's',\n",
       " 't',\n",
       " '▁of',\n",
       " 'f',\n",
       " ',',\n",
       " '▁I',\n",
       " '▁just',\n",
       " '▁have',\n",
       " '▁to',\n",
       " '▁sa',\n",
       " 'y',\n",
       " '▁that',\n",
       " '▁this',\n",
       " '▁was',\n",
       " '▁a',\n",
       " '▁large',\n",
       " '▁bag',\n",
       " '▁of',\n",
       " '▁dog',\n",
       " '▁food',\n",
       " ',',\n",
       " '▁so',\n",
       " '▁if',\n",
       " '▁you',\n",
       " \"'\",\n",
       " 've',\n",
       " '▁go',\n",
       " 't',\n",
       " '▁a',\n",
       " '▁small',\n",
       " 'er',\n",
       " '▁dog',\n",
       " '▁or',\n",
       " '▁a',\n",
       " '▁can',\n",
       " 'ine',\n",
       " '▁f',\n",
       " 'ri',\n",
       " 'end',\n",
       " '▁with',\n",
       " '▁a',\n",
       " '▁small',\n",
       " 'er',\n",
       " '▁a',\n",
       " 'pp',\n",
       " 'et',\n",
       " 'it',\n",
       " 'e',\n",
       " ',',\n",
       " '▁this',\n",
       " '▁bag',\n",
       " '▁will',\n",
       " '▁go',\n",
       " '▁a',\n",
       " '▁long',\n",
       " '▁way',\n",
       " '.',\n",
       " '▁A',\n",
       " 'l',\n",
       " 's',\n",
       " 'o',\n",
       " ',',\n",
       " '▁be',\n",
       " '▁car',\n",
       " 'e',\n",
       " 'ful',\n",
       " '▁when',\n",
       " '▁car',\n",
       " 'ry',\n",
       " 'ing',\n",
       " '▁this',\n",
       " ',',\n",
       " '▁as',\n",
       " '▁the',\n",
       " '▁to',\n",
       " 'p',\n",
       " '▁of',\n",
       " '▁this',\n",
       " '▁is',\n",
       " '▁re',\n",
       " 'se',\n",
       " 'al',\n",
       " 'able',\n",
       " '▁(',\n",
       " 'y',\n",
       " 'a',\n",
       " 'y',\n",
       " '!',\n",
       " ')',\n",
       " '▁with',\n",
       " '▁a',\n",
       " '▁',\n",
       " 'z',\n",
       " 'i',\n",
       " 'p',\n",
       " 'lo',\n",
       " 'ck',\n",
       " '▁to',\n",
       " 'p',\n",
       " '▁and',\n",
       " '▁this',\n",
       " '▁could',\n",
       " '▁',\n",
       " 's',\n",
       " 'c',\n",
       " 'ra',\n",
       " 't',\n",
       " 'ch',\n",
       " '▁your',\n",
       " '▁',\n",
       " 'ne',\n",
       " 'ck',\n",
       " '▁if',\n",
       " '▁you',\n",
       " \"'\",\n",
       " 're',\n",
       " '▁not',\n",
       " '▁a',\n",
       " '▁little',\n",
       " '▁w',\n",
       " 'ar',\n",
       " 'y',\n",
       " '.',\n",
       " '▁(',\n",
       " 'J',\n",
       " 'us',\n",
       " 't',\n",
       " '▁sa',\n",
       " 'y',\n",
       " 'ing',\n",
       " '▁this',\n",
       " '▁because',\n",
       " '▁I',\n",
       " '▁',\n",
       " 'end',\n",
       " 'ed',\n",
       " '▁up',\n",
       " '▁with',\n",
       " '▁a',\n",
       " '▁long',\n",
       " '▁',\n",
       " 's',\n",
       " 'c',\n",
       " 'ra',\n",
       " 't',\n",
       " 'ch',\n",
       " '▁down',\n",
       " '▁my',\n",
       " '▁',\n",
       " 'ne',\n",
       " 'ck',\n",
       " '▁from',\n",
       " '▁car',\n",
       " 'ry',\n",
       " 'ing',\n",
       " '▁this',\n",
       " '▁on',\n",
       " '▁my',\n",
       " '▁should',\n",
       " 'er',\n",
       " '▁and',\n",
       " '▁want',\n",
       " 'ed',\n",
       " '▁other',\n",
       " 's',\n",
       " '▁to',\n",
       " '▁a',\n",
       " 'v',\n",
       " 'o',\n",
       " 'id',\n",
       " '▁the',\n",
       " '▁sa',\n",
       " 'me',\n",
       " '▁f',\n",
       " 'ate',\n",
       " '.',\n",
       " ')',\n",
       " '▁My',\n",
       " '▁f',\n",
       " 'ri',\n",
       " 'end',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁can',\n",
       " 'ine',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁little',\n",
       " '▁p',\n",
       " 'i',\n",
       " 'ck',\n",
       " 'y',\n",
       " '▁about',\n",
       " '▁what',\n",
       " '▁he',\n",
       " '▁eat',\n",
       " 's',\n",
       " ',',\n",
       " '▁with',\n",
       " '▁dr',\n",
       " 'y',\n",
       " '▁dog',\n",
       " '▁food',\n",
       " '▁be',\n",
       " 'ing',\n",
       " '▁h',\n",
       " 'i',\n",
       " 's',\n",
       " '▁\"',\n",
       " 'la',\n",
       " 's',\n",
       " 't',\n",
       " '▁re',\n",
       " 's',\n",
       " 'or',\n",
       " 't',\n",
       " '\"',\n",
       " '.',\n",
       " '▁I',\n",
       " '▁f',\n",
       " 'i',\n",
       " 'g',\n",
       " 'ur',\n",
       " 'ed',\n",
       " '▁that',\n",
       " '▁if',\n",
       " '▁I',\n",
       " '▁could',\n",
       " '▁get',\n",
       " '▁this',\n",
       " '▁dog',\n",
       " '▁to',\n",
       " '▁eat',\n",
       " '▁and',\n",
       " '▁even',\n",
       " '▁re',\n",
       " 'm',\n",
       " 'o',\n",
       " 'te',\n",
       " 'ly',\n",
       " '▁enjoy',\n",
       " '▁this',\n",
       " '▁food',\n",
       " ',',\n",
       " '▁the',\n",
       " 'n',\n",
       " '▁it',\n",
       " '▁would',\n",
       " '▁be',\n",
       " '▁a',\n",
       " '▁pretty',\n",
       " '▁good',\n",
       " '▁recommend',\n",
       " 'ation',\n",
       " '.',\n",
       " '▁N',\n",
       " 'ow',\n",
       " '▁while',\n",
       " '▁he',\n",
       " '▁di',\n",
       " 'd',\n",
       " 'n',\n",
       " \"'\",\n",
       " 't',\n",
       " '▁take',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁B',\n",
       " 'en',\n",
       " 'e',\n",
       " 'ful',\n",
       " '▁like',\n",
       " '▁a',\n",
       " '▁f',\n",
       " 'ish',\n",
       " '▁to',\n",
       " '▁water',\n",
       " '▁or',\n",
       " '▁a',\n",
       " '▁cat',\n",
       " '▁to',\n",
       " '▁milk',\n",
       " ',',\n",
       " '▁he',\n",
       " '▁di',\n",
       " 'd',\n",
       " '▁eat',\n",
       " '▁it',\n",
       " ',',\n",
       " '▁which',\n",
       " '▁sa',\n",
       " 'y',\n",
       " 's',\n",
       " '▁quite',\n",
       " '▁a',\n",
       " '▁bit',\n",
       " '▁con',\n",
       " 'side',\n",
       " 'r',\n",
       " 'ing',\n",
       " '▁how',\n",
       " '▁he',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁about',\n",
       " '▁food',\n",
       " '.',\n",
       " '▁I',\n",
       " '▁don',\n",
       " \"'\",\n",
       " 't',\n",
       " '▁think',\n",
       " '▁that',\n",
       " '▁B',\n",
       " 'en',\n",
       " 'e',\n",
       " 'ful',\n",
       " '▁will',\n",
       " '▁be',\n",
       " 'com',\n",
       " 'e',\n",
       " '▁a',\n",
       " '▁regular',\n",
       " '▁add',\n",
       " 'i',\n",
       " 'tion',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁dog',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁di',\n",
       " 'et',\n",
       " '▁but',\n",
       " '▁that',\n",
       " '▁he',\n",
       " '▁eat',\n",
       " 's',\n",
       " '▁this',\n",
       " '▁me',\n",
       " 'an',\n",
       " 's',\n",
       " '▁that',\n",
       " '▁my',\n",
       " '▁f',\n",
       " 'ri',\n",
       " 'end',\n",
       " '▁will',\n",
       " '▁have',\n",
       " '▁another',\n",
       " '▁brand',\n",
       " '▁of',\n",
       " '▁dog',\n",
       " 'f',\n",
       " 'oo',\n",
       " 'd',\n",
       " '▁that',\n",
       " '▁he',\n",
       " '▁can',\n",
       " '▁g',\n",
       " 'u',\n",
       " 'ar',\n",
       " 'ant',\n",
       " 'e',\n",
       " 'e',\n",
       " '▁that',\n",
       " '▁h',\n",
       " 'i',\n",
       " 's',\n",
       " '▁dog',\n",
       " '▁will',\n",
       " '▁no',\n",
       " 'm',\n",
       " '▁on',\n",
       " '.',\n",
       " '▁This',\n",
       " '▁dog',\n",
       " '▁food',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁little',\n",
       " '▁on',\n",
       " '▁the',\n",
       " '▁ex',\n",
       " 'p',\n",
       " 'en',\n",
       " 's',\n",
       " 'ive',\n",
       " '▁',\n",
       " 'side',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁store',\n",
       " 's',\n",
       " '▁in',\n",
       " '▁my',\n",
       " '▁are',\n",
       " 'a',\n",
       " '▁and',\n",
       " '▁while',\n",
       " '▁I',\n",
       " '▁can',\n",
       " \"'\",\n",
       " 't',\n",
       " '▁g',\n",
       " 'u',\n",
       " 'ar',\n",
       " 'ant',\n",
       " 'e',\n",
       " 'e',\n",
       " '▁what',\n",
       " '▁the',\n",
       " '▁price',\n",
       " 's',\n",
       " '▁will',\n",
       " '▁be',\n",
       " '▁in',\n",
       " '▁your',\n",
       " '▁',\n",
       " 'ne',\n",
       " 'ck',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁w',\n",
       " 'oo',\n",
       " 'd',\n",
       " 's',\n",
       " '▁(',\n",
       " 'A',\n",
       " 'm',\n",
       " 'a',\n",
       " 'z',\n",
       " 'on',\n",
       " '▁price',\n",
       " '▁not',\n",
       " '▁with',\n",
       " 's',\n",
       " 't',\n",
       " 'and',\n",
       " 'ing',\n",
       " '▁since',\n",
       " '▁that',\n",
       " '▁can',\n",
       " '▁',\n",
       " 'ch',\n",
       " 'an',\n",
       " 'ge',\n",
       " '▁',\n",
       " 'ra',\n",
       " 'p',\n",
       " 'id',\n",
       " 'ly',\n",
       " '▁some',\n",
       " 't',\n",
       " 'im',\n",
       " 'es',\n",
       " ')',\n",
       " ',',\n",
       " '▁you',\n",
       " '▁',\n",
       " 'm',\n",
       " 'ight',\n",
       " '▁want',\n",
       " '▁to',\n",
       " '▁do',\n",
       " '▁a',\n",
       " '▁little',\n",
       " '▁price',\n",
       " 'ch',\n",
       " 'e',\n",
       " 'ck',\n",
       " 'ing',\n",
       " '▁on',\n",
       " '▁',\n",
       " 'v',\n",
       " 'ar',\n",
       " 'i',\n",
       " 'ous',\n",
       " '▁different',\n",
       " '▁dog',\n",
       " 'f',\n",
       " 'oo',\n",
       " 'd',\n",
       " 's',\n",
       " '.',\n",
       " '▁B',\n",
       " 'en',\n",
       " 'e',\n",
       " 'ful',\n",
       " '▁is',\n",
       " '▁definitely',\n",
       " '▁health',\n",
       " 'i',\n",
       " 'er',\n",
       " '▁than',\n",
       " '▁store',\n",
       " '▁brand',\n",
       " '▁dog',\n",
       " '▁food',\n",
       " ',',\n",
       " '▁but',\n",
       " '▁if',\n",
       " '▁you',\n",
       " \"'\",\n",
       " 're',\n",
       " '▁go',\n",
       " 'ing',\n",
       " '▁to',\n",
       " '▁sp',\n",
       " 'end',\n",
       " '▁the',\n",
       " '▁mo',\n",
       " 'ne',\n",
       " 'y',\n",
       " '▁the',\n",
       " 'n',\n",
       " '▁the',\n",
       " 're',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁some',\n",
       " '▁better',\n",
       " '▁stuff',\n",
       " '▁out',\n",
       " '▁the',\n",
       " 're',\n",
       " '▁that',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁a',\n",
       " '▁little',\n",
       " '▁more',\n",
       " '▁organic',\n",
       " '▁and',\n",
       " '▁',\n",
       " 'n',\n",
       " 'at',\n",
       " 'ur',\n",
       " 'al',\n",
       " '.',\n",
       " '▁C',\n",
       " 'as',\n",
       " 't',\n",
       " 'or',\n",
       " '▁',\n",
       " '&',\n",
       " '▁P',\n",
       " 'ol',\n",
       " 'lu',\n",
       " 'x',\n",
       " '▁has',\n",
       " '▁a',\n",
       " '▁',\n",
       " 's',\n",
       " 'l',\n",
       " 'ight',\n",
       " 'ly',\n",
       " '▁high',\n",
       " 'er',\n",
       " '▁pro',\n",
       " 'te',\n",
       " 'in',\n",
       " '▁',\n",
       " 'v',\n",
       " 'al',\n",
       " 'u',\n",
       " 'e',\n",
       " ',',\n",
       " '▁for',\n",
       " '▁ex',\n",
       " 'am',\n",
       " 'p',\n",
       " 'le',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.EncodeAsPieces(dev[ID]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First off, I just have to say that this was a large bag of dog food, so if you\\'ve got a smaller dog or a canine friend with a smaller appetite, this bag will go a long way. Also, be careful when carrying this, as the top of this is resealable (yay!) with a ziplock top and this could scratch your neck if you\\'re not a little wary. (Just saying this because I ended up with a long scratch down my neck from carrying this on my shoulder and wanted others to avoid the same fate.) My friend\\'s canine is a little picky about what he eats, with dry dog food being his \"last resort\". I figured that if I could get this dog to eat and even remotely enjoy this food, then it would be a pretty good recommendation. Now while he didn\\'t take to the Beneful like a fish to water or a cat to milk, he did eat it, which says quite a bit considering how he can be about food. I don\\'t think that Beneful will become a regular addition to the dog\\'s diet but that he eats this means that my friend will have another brand of dogfood that he can guarantee that his dog will nom on. This dog food is a little on the expensive side in the stores in my area and while I can\\'t guarantee what the prices will be in your neck of the woods (Amazon price not withstanding since that can change rapidly sometimes), you might want to do a little pricechecking on various different dogfoods. Beneful is definitely healthier than store brand dog food, but if you\\'re going to spend the money then there\\'s some better stuff out there that\\'s a little more organic and natural. Castor & Pollux has a slightly higher protein value, for example.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.DecodePieces(tokenizer.EncodeAsPieces(dev[ID]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
