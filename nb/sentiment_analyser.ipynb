{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0-rc0\n",
    "#!pip install --upgrade spacy\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.keras as K\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import normalize as scikit_normalize\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "from IPython.display import display,HTML,IFrame,clear_output\n",
    "from ipywidgets import widgets, interact\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER='/Users/matejkvassay/data/z/model/'\n",
    "DEMO_DATA='/Users/matejkvassay/data/z/reviews_demo.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_SUMMARY='summary'\n",
    "KEY_CONTENT='text'\n",
    "VECTORIZER_SUMMARY_FNAME='vectorizer_summary.pickle'\n",
    "VECTORIZER_CONTENT_FNAME='vectorizer_text.pickle'\n",
    "KERAS_MODEL_FNAME='keras_regressor.h5'\n",
    "LOSS_F_NAME='penalized_loss'\n",
    "\n",
    "def penalized_loss(y_true, y_pred):\n",
    "    return K.backend.mean(K.backend.square(K.backend.abs(y_true - y_pred))/y_true)\n",
    "\n",
    "\n",
    "class SentimentPredictionModel:\n",
    "    def __init__(self,model_folder):\n",
    "        with open(os.path.join(model_folder, VECTORIZER_SUMMARY_FNAME),'rb') as f:\n",
    "            self.vectorizer_summary=pickle.load(f)\n",
    "        with open(os.path.join(model_folder,VECTORIZER_CONTENT_FNAME), 'rb') as f:\n",
    "            self.vectorizer_text=pickle.load(f)\n",
    "        self.model = K.models.load_model(os.path.join(model_folder,KERAS_MODEL_FNAME),\n",
    "                                          custom_objects={LOSS_F_NAME: penalized_loss})\n",
    "        \n",
    "    @staticmethod\n",
    "    def _tf_predict(vectorizer,dataset,key):\n",
    "        features=vectorizer.transform([' '.join(x[key]) for x in dataset])\n",
    "        return features\n",
    "\n",
    "    def _extract_features(self,dataset):\n",
    "        summ_vecs=self._tf_predict(self.vectorizer_summary,dataset, KEY_SUMMARY)\n",
    "        text_vecs=self._tf_predict(self.vectorizer_text,dataset, KEY_CONTENT)\n",
    "        return scikit_normalize(hstack([summ_vecs, text_vecs],format='csr'))\n",
    "\n",
    "    @staticmethod\n",
    "    def _fix_ratings_over_limit(y_pred,cast_f=float):\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            # fix values over limit (>5, <1)\n",
    "            if y_pred[i]>5:\n",
    "                y_pred[i]=cast_f(5)\n",
    "            if y_pred[i]<1:\n",
    "                y_pred[i]=cast_f(1)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self, dataset_tokenized, fix_overlimit=False,\n",
    "                integer=False):\n",
    "        X_pred=self._extract_features(dataset_tokenized)\n",
    "        y_pred=self.model.predict(X_pred.todense())\n",
    "        if integer:\n",
    "            y_pred= np.rint(y_pred)\n",
    "            if fix_overlimit:\n",
    "                y_pred=self._fix_ratings_over_limit(y_pred,cast_f=int)\n",
    "        else:\n",
    "            if fix_overlimit:\n",
    "                y_pred=self._fix_ratings_over_limit(y_pred,cast_f=float)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matejkvassay/env/main/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/matejkvassay/env/main/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.21.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 s, sys: 382 ms, total: 1.93 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model=SentimentPredictionModel(MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacy NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.6 s, sys: 1.16 s, total: 8.77 s\n",
      "Wall time: 9.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spacy_nlp=spacy.load('en_core_web_lg',disable=[\"ner\",\"tagger\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPredictor:\n",
    "    def __init__(self,spacy_nlp,model):\n",
    "        self.model=model\n",
    "        self.nlp = spacy_nlp\n",
    "        \n",
    "    def _preprocess_text(self,text):\n",
    "        return tuple([str(x.lemma_) for x in self.nlp(text)])\n",
    "    \n",
    "    def detect_sentiment(self,review_summary,review_content,binary=False,round_to_closest=True):\n",
    "        summ=self._preprocess_text(review_summary)\n",
    "        cont=self._preprocess_text(review_content)\n",
    "        prediction=self.model.predict([{KEY_SUMMARY: summ, KEY_CONTENT:cont}])\n",
    "        prediction=np.rint(prediction[0][0])\n",
    "        if prediction> 5:\n",
    "            prediction=5.0\n",
    "        if prediction < 1:\n",
    "            prediction=1.0\n",
    "        if binary:\n",
    "            prediction = 1.0 if prediction <3 else 0.0\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_predictor=SentimentPredictor(spacy_nlp,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DEMO_DATA, 'rb') as f:\n",
    "    data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_spacy_format(sample,prediction):\n",
    "    label_map={1.0:'1',\n",
    "          2.0:'2',\n",
    "          3.0:'3',\n",
    "          4.0:'4',\n",
    "          5.0:'5'}\n",
    "    title= 'Predicted rating: {}/5'.format(int(prediction))\n",
    "    title2='\\n\\nTrue rating: {}/5'.format(str(int(sample['score'])))\n",
    "    summ = '\\n\\n'+sample['summary']+'\\n\\n'\n",
    "    text = '\\n\\n'+sample['text']+'\\n\\n'\n",
    "    review_spacy_format = {'text':title+title2+summ+text}\n",
    "    ents = {'ents':[]}\n",
    "\n",
    "    ents['ents'].append({'start':0,'end':len(title),'label':label_map[prediction]})\n",
    "    ents['ents'].append({'start':len(title),'end':len(title)+len(title2),'label':label_map[sample['score']]})\n",
    "    ents['ents'].append({'start':len(title)+len(title2),'end':len(title)+len(title2)+len(summ),'label':'S'})\n",
    "    ents['ents'].append({'start':len(title)+len(title2)+len(summ),'end':len(title)+len(title2)+len(summ)+len(text),'label':'C'})\n",
    "        \n",
    "    review_spacy_format.update(ents)\n",
    "    review_spacy_format['title']=('Sentiment analysis of Amazon food review:')\n",
    "    return review_spacy_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_display(review_id):\n",
    "    COLOR_MAPPING={\n",
    "        '5':'#3ADF00',\n",
    "         '4':'#4B8A08',\n",
    "        '3':'#FFFF00',\n",
    "        '2':'#FAAC58',\n",
    "        '1':'#FF0000',\n",
    "        'S':'#F5F5F5',\n",
    "        'C':'#F5F5F5'}\n",
    "    sample=data[review_id]\n",
    "    prediction=sentiment_predictor.detect_sentiment(sample['summary'],sample['text'])\n",
    "    formatted=to_spacy_format(sample,prediction)\n",
    "    display(HTML(displacy.render(formatted,\n",
    "                             manual=True,\n",
    "                             style='ent',\n",
    "                             options={'colors':COLOR_MAPPING})))\n",
    "\n",
    "def show_next(_):\n",
    "    clear_output()\n",
    "    button_display()\n",
    "    predict_display(np.random.choice(len(data)))\n",
    "\n",
    "    \n",
    "def button_display():\n",
    "    button=widgets.Button(description='Predict random')\n",
    "    button.on_click(show_next)\n",
    "    display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54784a1aa5c948c58f92633e98956b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict random', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"margin: 0\">Sentiment analysis of Amazon food review:</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #FAAC58; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Predicted rating: 2/5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">2</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #FFFF00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "True rating: 3/5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">3</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #F5F5F5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "the canadian standard for pure is NOT 100 %\n",
       "\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">S</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #F5F5F5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "to the best of my knowledge Maple syrup from Canada only needs 80% maple to be considered pure. NY 90% , Vermont 100%  I wonder if this product ignores Canada's Standard.\n",
       "\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">C</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_next('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
